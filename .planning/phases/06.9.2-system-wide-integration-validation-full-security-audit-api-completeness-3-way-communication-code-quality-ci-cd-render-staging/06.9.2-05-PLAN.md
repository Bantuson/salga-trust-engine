---
phase: 06.9.2-system-wide-integration-validation
plan: 05
type: execute
wave: 2
depends_on:
  - 06.9.2-01
  - 06.9.2-02
files_modified:
  - tests/test_3way_communication.py
  - tests/test_crew_server_integration.py
autonomous: true
requirements:
  - AI-01
  - AI-02
  - AI-03
  - TKT-01
  - TKT-02
  - SEC-05
  - PLAT-01
  - PLAT-02
  - PLAT-03
  - PLAT-04
  - SEC-01

must_haves:
  truths:
    - "Agent ticket creation produces a ticket visible in the municipal dashboard query"
    - "Municipal ticket stats aggregate correctly in public dashboard views"
    - "GBV tickets created by agents are invisible in public stats"
    - "Crew server chat endpoint routes messages through ManagerCrew to specialist crews"
    - "Multi-tenant isolation prevents cross-municipality ticket visibility"
  artifacts:
    - path: "tests/test_3way_communication.py"
      provides: "End-to-end 3-way communication flow tests"
      min_lines: 80
    - path: "tests/test_crew_server_integration.py"
      provides: "Crew server endpoint behavioral tests"
      min_lines: 60
  key_links:
    - from: "tests/test_3way_communication.py"
      to: "src/agents/tools/ticket_tool.py"
      via: "ticket creation mock"
      pattern: "ticket_tool"
    - from: "tests/test_3way_communication.py"
      to: "src/services/public_metrics_service.py"
      via: "public stats aggregation"
      pattern: "public_metrics"
    - from: "tests/test_crew_server_integration.py"
      to: "src/api/v1/crew_server.py"
      via: "TestClient for crew_app"
      pattern: "crew_app"
---

<objective>
Validate the 3-way communication flow (agent creates ticket -> municipal dashboard receives -> public stats reflect) and crew server endpoint behavior.

Purpose: Research identified that the 3-way flow was never tested end-to-end. Each piece works in isolation but the full data path from WhatsApp agent ticket creation to municipal dashboard visibility to public transparency stats has never been validated. This plan tests that flow at the unit/integration level without requiring live LLM calls.

Output: Integration tests proving the data flows correctly across all 3 systems, plus crew server behavioral tests.
</objective>

<execution_context>
@C:/Users/Bantu/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Bantu/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@src/api/v1/crew_server.py
@src/agents/tools/ticket_tool.py
@src/services/public_metrics_service.py
@src/api/v1/tickets.py
@src/api/v1/public.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: 3-way communication flow integration tests</name>
  <files>tests/test_3way_communication.py</files>
  <action>
Create tests/test_3way_communication.py that validates the end-to-end data flow. These are unit-level integration tests using mocked external services (no live LLM, no live Supabase).

**Test 1: Agent creates ticket -> ticket exists in DB**
```python
async def test_agent_ticket_creation_produces_db_record():
    """
    Simulate: MunicipalIntakeCrew's ticket_tool creates a ticket.
    Verify: Ticket record exists with correct fields (tracking_number, category, status='open',
    tenant_id set, location if provided).

    Mock: Supabase admin client (ticket_tool uses admin client for direct insertion).
    Verify: The insert call was made with correct data shape.
    """
```

**Test 2: Created ticket visible in municipal dashboard query**
```python
async def test_agent_created_ticket_visible_in_dashboard():
    """
    Simulate: Ticket exists in DB (from agent creation).
    Call: GET /api/v1/tickets with authenticated manager user.
    Verify: Ticket appears in response list with correct fields.

    Mock: Database query returns ticket created by agent.
    Verify: Dashboard ticket list includes the agent-created ticket.
    """
```

**Test 3: Non-GBV ticket stats appear in public metrics**
```python
async def test_non_gbv_ticket_in_public_stats():
    """
    Simulate: Standard (non-GBV) ticket exists in DB.
    Call: GET /api/v1/public/stats
    Verify: Ticket counted in municipality stats, category breakdown correct.

    Mock: Public metrics service returns aggregated data including the ticket.
    """
```

**Test 4: GBV ticket invisible in public metrics**
```python
async def test_gbv_ticket_excluded_from_public_stats():
    """
    Simulate: GBV ticket (is_sensitive=True) exists in DB.
    Call: GET /api/v1/public/stats
    Verify: GBV ticket NOT counted in public stats (SEC-05 Layer 5).

    Mock: Public metrics service with is_sensitive filter.
    """
```

**Test 5: Multi-tenant isolation in ticket visibility**
```python
async def test_cross_municipality_ticket_isolation():
    """
    Simulate: Ticket in municipality A.
    Call: GET /api/v1/tickets with manager from municipality B.
    Verify: Ticket from municipality A NOT visible to municipality B manager.
    """
```

**Test 6: WhatsApp notification dispatched on status change**
```python
async def test_status_change_dispatches_whatsapp_notification():
    """
    Simulate: Ticket status changes from 'open' to 'in_progress'.
    Verify: WhatsApp notification Celery task is enqueued (mocked).
    """
```

**Test 7: Full flow simulation — agent -> dashboard -> public**
```python
async def test_full_3way_flow_simulation():
    """
    End-to-end simulation:
    1. Mock agent creating ticket via ticket_tool (returns tracking number)
    2. Mock dashboard query including that ticket
    3. Mock public stats aggregation including that ticket
    4. Verify data consistency: same ticket_id appears at all 3 layers
    5. Verify GBV exclusion: sensitive ticket absent from public layer
    """
```

Use existing conftest.py patterns. Mock Supabase client, database sessions, and Celery tasks. Do NOT call real LLMs or external services.
  </action>
  <verify>`pytest tests/test_3way_communication.py -v --timeout=120 2>&1 | tail -20` — tests execute and pass</verify>
  <done>3-way flow validated: agent ticket creation -> municipal dashboard visibility -> public stats aggregation. GBV exclusion verified at public layer. Multi-tenant isolation confirmed.</done>
</task>

<task type="auto">
  <name>Task 2: Crew server endpoint behavioral tests</name>
  <files>tests/test_crew_server_integration.py</files>
  <action>
Create tests/test_crew_server_integration.py that tests crew_server endpoints at the HTTP level using TestClient(crew_app).

**Test 1: Health endpoint**
```python
def test_health_check():
    """GET /api/v1/health returns 200 with status=ok."""
    from src.api.v1.crew_server import crew_app
    from fastapi.testclient import TestClient
    client = TestClient(crew_app)
    response = client.get("/api/v1/health")
    assert response.status_code == 200
    assert response.json()["status"] == "ok"
```

**Test 2: Chat endpoint requires API key (when configured)**
```python
def test_chat_requires_api_key():
    """POST /api/v1/chat returns 401 without valid X-API-Key when key is configured."""
    # Temporarily set CREW_SERVER_API_KEY to a test value
```

**Test 3: Chat endpoint accepts valid request (mock crew)**
```python
async def test_chat_valid_request():
    """POST /api/v1/chat with valid phone+message routes through agent (mocked)."""
    # Mock ManagerCrew.kickoff to return a fixed response
    # Verify: response has reply, agent_name, session_status, debug fields
```

**Test 4: Session reset clears state**
```python
async def test_session_reset_clears_state():
    """POST /api/v1/session/reset clears conversation state for phone number."""
```

**Test 5: Chat input validation**
```python
def test_chat_rejects_long_message():
    """POST /api/v1/chat with message > 2000 chars returns 422."""

def test_chat_rejects_invalid_phone():
    """POST /api/v1/chat with invalid phone returns 422."""
```

**Test 6: Chat response sanitization**
```python
async def test_chat_sanitizes_llm_artifacts():
    """Agent response with LLM artifacts (Thought:, Action:, etc.) is cleaned."""
    # Mock crew to return raw output with artifacts
    # Verify: reply in response is clean (no "Thought:", "Action:", etc.)
```

**Test 7: GBV debug redaction**
```python
async def test_gbv_debug_redacted():
    """GBV conversations only show metadata in debug (no conversation content)."""
    # Mock agent returning gbv_intake response
    # Verify: debug dict has agent_name, turn_count, session_status ONLY
```

**Test 8: Language detection**
```python
async def test_language_preference_detection():
    """Explicit language preference ('isiZulu') is detected and used."""
```

**Test 9: Rate limiting on chat**
```python
def test_chat_rate_limit():
    """Chat endpoint enforces rate limiting."""
    # Note: This depends on Plan 01 adding rate limiting to crew_server
    # If rate limiting is configured, rapid requests should eventually get 429
```

Mock all CrewAI crews and external services. Use InMemoryConversationManager (already the default when Redis is unavailable).
  </action>
  <verify>`pytest tests/test_crew_server_integration.py -v --timeout=120 2>&1 | tail -20` — tests execute and pass</verify>
  <done>Crew server behavioral tests cover health, auth, chat routing, sanitization, GBV redaction, input validation, and language detection</done>
</task>

</tasks>

<verification>
- All test files created and importable
- `pytest tests/test_3way_communication.py tests/test_crew_server_integration.py -v` — all tests pass
- 3-way flow validated at all 3 layers
- GBV exclusion verified in public stats
- Crew server endpoints tested for behavior and failure modes
</verification>

<success_criteria>
- 3-way communication validated: agent creates ticket -> dashboard shows ticket -> public stats include ticket
- GBV firewall confirmed at public layer (sensitive tickets excluded from public stats)
- Crew server tested: health, auth, chat routing, sanitization, input validation
- Multi-tenant isolation verified in ticket visibility
- All tests pass without requiring live LLM or external services
</success_criteria>

<output>
After completion, create `.planning/phases/06.9.2-system-wide-integration-validation-full-security-audit-api-completeness-3-way-communication-code-quality-ci-cd-render-staging/06.9.2-05-SUMMARY.md`
</output>
