---
phase: 10.3-crewai-agent-rebuild-and-llm-evaluation-framework
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/agents_old/
  - src/agents/__init__.py
  - src/agents/llm.py
  - src/agents/config/agents.yaml
  - src/agents/config/tasks.yaml
  - src/agents/crews/__init__.py
  - src/agents/crews/base_crew.py
  - src/agents/flows/__init__.py
  - src/agents/flows/state.py
  - src/agents/tools/__init__.py
  - src/agents/prompts/__init__.py
  - tests/agents/__init__.py
  - tests/agents/conftest.py
  - tests/evals/__init__.py
  - tests/evals/scenarios/__init__.py
  - tests/evals/reports/.gitkeep
  - pyproject.toml
autonomous: true
requirements:
  - AI-01
  - AI-02

must_haves:
  truths:
    - "Old agent code is archived and accessible but not imported by any active module"
    - "New src/agents/ directory has clean structure matching research architecture"
    - "deepeval is installed and importable"
    - "Test fixtures provide mock LLM and mock tools for agent unit tests"
    - "IntakeState Pydantic model defines conversation state schema"
    - "BaseCrew provides shared YAML loading and sequential crew pattern"
  artifacts:
    - path: "src/agents_old/"
      provides: "Archive of old agent code for reference"
    - path: "src/agents/llm.py"
      provides: "LLM factory functions (get_deepseek_llm, get_routing_llm)"
      exports: ["get_deepseek_llm", "get_routing_llm"]
    - path: "src/agents/crews/base_crew.py"
      provides: "Shared BaseCrew with YAML loading, sequential Process, parse_result"
      contains: "class BaseCrew"
    - path: "src/agents/flows/state.py"
      provides: "IntakeState Pydantic model for Flow state management"
      contains: "class IntakeState"
    - path: "tests/agents/conftest.py"
      provides: "Shared test fixtures (mock_llm, mock_tools, mock_conversation_manager)"
  key_links:
    - from: "src/agents/llm.py"
      to: "crewai.LLM"
      via: "import and factory instantiation"
      pattern: "LLM\\(model="
    - from: "src/agents/crews/base_crew.py"
      to: "src/agents/config/agents.yaml"
      via: "YAML loading for agent definitions"
      pattern: "yaml\\.safe_load"
---

<objective>
Archive existing agent code and scaffold the new agent architecture from scratch.

Purpose: Establish a clean foundation for the agent rebuild. The old code is moved to src/agents_old/ for reference but is no longer imported. The new directory structure follows the Flow-as-router + sequential specialist Crews architecture from research. deepeval is installed for trajectory evaluation. Test infrastructure is scaffolded with shared fixtures.

Output: Clean src/agents/ scaffold, archived old code, installed deepeval, test fixtures ready

Note: This plan touches 15 files but 7 are empty __init__.py scaffolding (agents/, crews/, flows/, tools/, prompts/, tests/agents/, tests/evals/). Actual implementation work is concentrated in 8 files.
</objective>

<execution_context>
@C:/Users/Bantu/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Bantu/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/10.3-crewai-agent-rebuild-and-llm-evaluation-framework/10.3-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Archive old agents and scaffold new directory structure</name>
  <files>
    src/agents_old/
    src/agents/__init__.py
    src/agents/llm.py
    src/agents/config/agents.yaml
    src/agents/config/tasks.yaml
    src/agents/crews/__init__.py
    src/agents/crews/base_crew.py
    src/agents/flows/__init__.py
    src/agents/flows/state.py
    src/agents/tools/__init__.py
    src/agents/prompts/__init__.py
  </files>
  <action>
    1. Archive old code: `git mv src/agents src/agents_old`. This preserves git history.

    2. Create new `src/agents/` directory structure:
       ```
       src/agents/
       ├── __init__.py          # Empty or minimal
       ├── llm.py               # LLM factory (copy from agents_old, update)
       ├── config/
       │   ├── agents.yaml      # Start empty, populated per-agent in later plans
       │   └── tasks.yaml       # Start empty, populated per-agent in later plans
       ├── crews/
       │   ├── __init__.py
       │   └── base_crew.py     # Rebuilt BaseCrew
       ├── flows/
       │   ├── __init__.py
       │   └── state.py         # IntakeState Pydantic model
       ├── tools/
       │   └── __init__.py      # Empty — tools copied/rebuilt per-agent in later plans
       └── prompts/
           └── __init__.py      # Empty — prompts rebuilt per-agent in later plans
       ```

    3. `src/agents/llm.py` — Two factory functions:
       - `get_deepseek_llm()` → returns `crewai.LLM(model="deepseek/deepseek-chat", base_url=settings.DEEPSEEK_BASE_URL, api_key=settings.DEEPSEEK_API_KEY)` for specialist conversation agents
       - `get_routing_llm()` → returns `crewai.LLM(model="gpt-4o-mini", api_key=settings.OPENAI_API_KEY)` for intent classification and tool-heavy agents (Auth, Manager routing)
       - Both use lazy instantiation (new LLM per call, not cached — per research anti-pattern on reusing LLM objects)
       - Import settings from `src.core.config`

    4. `src/agents/crews/base_crew.py` — Rebuilt BaseCrew class:
       - `__init__(self, language: str = "en", llm=None)` — stores language and LLM
       - `_load_yaml(filename: str) -> dict` — class method, loads from `src/agents/config/`
       - `create_crew(self, context: dict) -> Crew` — abstract method, subclasses override
       - `async kickoff(self, context: dict) -> dict` — creates crew via create_crew(), calls crew.kickoff(inputs=context), returns parsed result
       - `parse_result(self, result) -> dict` — extracts from CrewOutput, handles pydantic output, falls back to raw string parsing
       - `_repair_from_raw(raw: str) -> dict` — module-level helper for extracting structured data from raw LLM output when Pydantic fails
       - Process: ALWAYS `Process.sequential`
       - Memory: ALWAYS `memory=False` (conversation history via string injection)
       - Verbose: `verbose=False`
       - Keep the existing sanitization patterns from agents_old/crews/base_crew.py (copy _repair_from_raw, parse_result logic) but simplify — remove all hierarchical/delegation-related code

    5. `src/agents/flows/state.py` — IntakeState Pydantic model:
       ```python
       from pydantic import BaseModel

       class IntakeState(BaseModel):
           message: str = ""
           phone: str = ""
           language: str = "en"
           intent: str = "unknown"  # "auth" | "municipal" | "ticket_status" | "gbv"
           routing_phase: str = "manager"
           session_status: str = "none"  # "none" | "active" | "expired" | "otp_pending"
           user_id: str | None = None
           conversation_history: str = "(none)"
           result: dict = {}
           pending_intent: str = ""  # Carries citizen's original intent through auth
       ```

    6. `src/agents/config/agents.yaml` and `tasks.yaml` — Start with empty YAML structure:
       ```yaml
       # agents.yaml — Agent persona definitions
       # Populated per-agent in plans 03-07
       ```

    7. Update any direct imports of `src.agents` in other modules. Key files that import from agents:
       - `src/api/v1/crew_server.py` — imports crews, flows, tools. These imports will break until rebuilt. For now, just ensure the archive is clean. crew_server.py will be rebuilt in Plan 06.
       - `src/api/v1/messages.py` — may import IntakeFlow
       - `src/api/v1/whatsapp.py` / `src/services/whatsapp_service.py` — may import crews
       NOTE: Do NOT fix these imports yet — they will be rebuilt in later plans. The archive step intentionally breaks them to force the clean rebuild.

    8. Install deepeval: Add `deepeval` to pyproject.toml `[project.optional-dependencies]` under a new `eval` group:
       ```
       eval = ["deepeval>=1.0"]
       ```
       Then run: `pip install -e ".[eval]"`
  </action>
  <verify>
    <automated>python -c "from src.agents.llm import get_deepseek_llm, get_routing_llm; from src.agents.flows.state import IntakeState; from src.agents.crews.base_crew import BaseCrew; print('All imports OK')"</automated>
    <manual>Verify src/agents_old/ contains all old agent files; src/agents/ has clean new structure</manual>
  </verify>
  <done>Old agent code archived to src/agents_old/. New src/agents/ has llm.py, base_crew.py, state.py, empty config YAMLs. deepeval installed. All new module imports succeed.</done>
</task>

<task type="auto">
  <name>Task 2: Create agent test infrastructure and shared fixtures</name>
  <files>
    tests/agents/__init__.py
    tests/agents/conftest.py
    tests/evals/__init__.py
    tests/evals/scenarios/__init__.py
    tests/evals/reports/.gitkeep
  </files>
  <action>
    1. Create `tests/agents/` package:
       - `__init__.py` — empty
       - `conftest.py` — shared pytest fixtures:
         ```python
         import pytest
         from unittest.mock import MagicMock, AsyncMock, patch
         import os

         # Set fake API keys before any CrewAI imports
         os.environ.setdefault("OPENAI_API_KEY", "fake-key-for-tests")
         os.environ.setdefault("DEEPSEEK_API_KEY", "fake-key-for-tests")

         @pytest.fixture
         def mock_llm():
             """Mock crewai.LLM that returns predictable responses."""
             llm = MagicMock()
             llm.call.return_value = "auth"  # Default: classify as auth intent
             return llm

         @pytest.fixture
         def mock_conversation_manager():
             """Mock ConversationManager for session state."""
             mgr = MagicMock()
             mgr.get_or_create_state.return_value = MagicMock(
                 turns=[], routing_phase="manager", session_status="none",
                 user_id=None, language="en", pending_intent=""
             )
             mgr.save_state = MagicMock()
             mgr.append_turn = MagicMock()
             mgr.clear_session = MagicMock()
             return mgr

         @pytest.fixture
         def auth_context():
             """Standard auth agent context dict."""
             return {
                 "message": "Hi, I want to report a pothole",
                 "phone": "+27821234567",
                 "language": "en",
                 "session_status": "none",
                 "conversation_history": "(none)",
                 "user_id": "",
             }

         @pytest.fixture
         def municipal_context():
             """Standard municipal agent context dict."""
             return {
                 "message": "There is a broken pipe on Main Road",
                 "phone": "+27821234567",
                 "language": "en",
                 "conversation_history": "User: Hi\\nGugu: Welcome!",
                 "user_id": "user-uuid-123",
                 "user_name": "Thabo",
             }

         @pytest.fixture
         def gbv_context():
             """Standard GBV agent context dict."""
             return {
                 "message": "I need help, my partner is threatening me",
                 "phone": "+27821234567",
                 "language": "en",
                 "conversation_history": "(none)",
                 "user_id": "user-uuid-456",
             }

         @pytest.fixture
         def ticket_status_context():
             """Standard ticket status context dict."""
             return {
                 "message": "What is the status of TKT-20260225-abc123?",
                 "phone": "+27821234567",
                 "language": "en",
                 "conversation_history": "(none)",
                 "user_id": "user-uuid-789",
                 "tracking_number": "TKT-20260225-abc123",
             }
         ```

    2. Create `tests/evals/` package:
       - `__init__.py` — empty
       - `scenarios/__init__.py` — empty (scenarios added in Plan 02)
       - `reports/.gitkeep` — directory for timestamped eval reports

    3. Verify test infrastructure by running: `pytest tests/agents/ --collect-only` (should find conftest but no tests yet — that's expected)
  </action>
  <verify>
    <automated>python -c "import tests.agents.conftest; import tests.evals; print('Test infrastructure OK')" && pytest tests/agents/ --collect-only -q 2>&1 | head -5</automated>
  </verify>
  <done>tests/agents/ has conftest.py with 5 shared fixtures (mock_llm, mock_conversation_manager, auth_context, municipal_context, gbv_context, ticket_status_context). tests/evals/ scaffolded with scenarios/ and reports/ directories.</done>
</task>

</tasks>

<verification>
- `python -c "from src.agents.llm import get_deepseek_llm, get_routing_llm"` succeeds
- `python -c "from src.agents.flows.state import IntakeState; s = IntakeState(); print(s.intent)"` prints "unknown"
- `python -c "from src.agents.crews.base_crew import BaseCrew"` succeeds
- `ls src/agents_old/crews/` shows old crew files
- `pytest tests/agents/ --collect-only` runs without error
</verification>

<success_criteria>
- Old agent code fully archived to src/agents_old/
- New src/agents/ scaffold has all subdirectories with __init__.py files
- llm.py exports get_deepseek_llm() and get_routing_llm()
- IntakeState Pydantic model has all required fields with defaults
- BaseCrew provides create_crew/kickoff/parse_result pattern
- deepeval installed and importable
- Test conftest.py provides shared fixtures for all agent tests
</success_criteria>

<output>
After completion, create `.planning/phases/10.3-crewai-agent-rebuild-and-llm-evaluation-framework/10.3-01-SUMMARY.md`
</output>
