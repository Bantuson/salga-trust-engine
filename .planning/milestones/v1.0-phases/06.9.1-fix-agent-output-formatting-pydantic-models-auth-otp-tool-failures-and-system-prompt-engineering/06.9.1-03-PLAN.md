---
phase: 06.9.1-fix-agent-output-formatting-pydantic-models-auth-otp-tool-failures-and-system-prompt-engineering
plan: 03
type: execute
wave: 2
depends_on: ["06.9.1-02"]
files_modified:
  - src/api/v1/crew_server.py
  - src/agents/crews/manager_crew.py
autonomous: true
requirements: [AI-01, AI-02, AI-07]

must_haves:
  truths:
    - "Delegation text like 'As the Municipal Services Manager...' is stripped before reaching citizens"
    - "sanitize_reply() catches all known delegation artifact patterns"
    - "ManagerCrew.parse_result() strips delegation narration from raw output"
    - "crew_server.py validates Pydantic model output before sanitizing for citizens"
    - "GBV responses always include emergency numbers even after sanitization"
    - "ManagerCrew verbose set to False for production"
  artifacts:
    - path: "src/api/v1/crew_server.py"
      provides: "Enhanced sanitize_reply with delegation patterns + Pydantic validation layer"
      contains: "_DELEGATION_ARTIFACT_PATTERNS"
    - path: "src/agents/crews/manager_crew.py"
      provides: "Delegation text filter in parse_result() + verbose=False"
      contains: "_DELEGATION_PATTERNS"
  key_links:
    - from: "src/api/v1/crew_server.py"
      to: "src/agents/crews/manager_crew.py"
      via: "crew_server calls manager_crew.kickoff() then sanitize_reply()"
      pattern: "sanitize_reply"
    - from: "src/api/v1/crew_server.py"
      to: "src/agents/crews/base_crew.py"
      via: "Imports AgentResponse for Pydantic validation layer"
      pattern: "AgentResponse"
---

<objective>
Add code-level delegation text filtering to both ManagerCrew.parse_result() and crew_server.py sanitize_reply(), plus a Pydantic validation layer in crew_server.py that validates crew output before sending to citizens.

Purpose: This is the belt-and-suspenders defense layer. Even with hardened prompts (Plan 01), LLMs occasionally revert to narrating their reasoning under certain inputs. Code-level filtering ensures delegation text never reaches citizens regardless of prompt compliance. The Pydantic validation layer ensures structured output from all crews is validated before sanitization.

Output: Enhanced sanitize_reply() with delegation patterns, ManagerCrew.parse_result() with delegation stripping, and Pydantic-aware validation in crew_server.py.
</objective>

<execution_context>
@C:/Users/Bantu/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Bantu/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06.9.1-fix-agent-output-formatting-pydantic-models-auth-otp-tool-failures-and-system-prompt-engineering/06.9.1-RESEARCH.md
@.planning/phases/06.9.1-fix-agent-output-formatting-pydantic-models-auth-otp-tool-failures-and-system-prompt-engineering/06.9.1-02-SUMMARY.md
@src/api/v1/crew_server.py
@src/agents/crews/manager_crew.py
@src/agents/crews/base_crew.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add delegation artifact patterns to sanitize_reply() and Pydantic validation layer to crew_server.py</name>
  <files>
    src/api/v1/crew_server.py
  </files>
  <action>
    **Change 1: Add _DELEGATION_ARTIFACT_PATTERNS list after existing _LLM_ARTIFACT_PATTERNS:**

    ```python
    # Patterns indicating internal agent delegation text (never citizen-facing)
    _DELEGATION_ARTIFACT_PATTERNS = [
        r"^As the .{0,50} Manager.*$",             # Role narration: "As the Municipal Services Manager..."
        r"^As the .{0,50} Specialist.*$",           # Role narration: "As the auth specialist..."
        r"^Here is the (?:complete|correct).*procedure.*$",  # Delegation instructions
        r"^For you,? Gugu.*$",                      # Misidentified citizen as agent
        r"^Dear Gugu.*$",                           # Same
        r"^Procedure for (?:Gugu|the specialist).*$",  # Internal routing
        r"^I am (?:now )?delegating.*$",            # Delegation narration
        r"^(?:Routing|Delegating) to.*$",           # Internal routing
        r"^The manager has.*$",                     # Manager reference leaked
        r"^I have been assigned.*$",                # Assignment narration
        r"^(?:My|The) task is to.*$",               # Task narration
        r"^According to (?:my|the) (?:instructions|assignment).*$",  # Instructions narration
    ]
    ```

    **Change 2: Update sanitize_reply() to use both pattern lists:**

    In the line-by-line filtering section (the `for line in lines` loop), update to check BOTH lists:
    ```python
    for line in lines:
        stripped = line.strip()
        if not stripped:
            continue
        skip = False
        # Check BOTH artifact pattern lists
        for pattern in _LLM_ARTIFACT_PATTERNS + _DELEGATION_ARTIFACT_PATTERNS:
            if re.match(pattern, stripped, re.IGNORECASE):
                # Special case: "Final Answer:" prefix — keep content after it
                if pattern == r"^Final Answer:?\s*":
                    stripped = re.sub(r"^Final Answer:?\s*", "", stripped, flags=re.IGNORECASE)
                    if stripped:
                        clean_lines.append(stripped)
                skip = True
                break
        if not skip:
            clean_lines.append(line)
    ```

    **Change 3: Add GBV emergency number safety check after sanitization:**

    After the existing sanitization in sanitize_reply(), before the final return, add:
    ```python
    # GBV safety: if agent is GBV and emergency numbers were stripped, re-add them
    if agent_name in ("gbv_intake", "gbv") and "10111" not in text and "0800 150 150" not in text:
        text = text.rstrip() + "\n\nIf you are in immediate danger, call SAPS: 10111 | GBV Helpline: 0800 150 150"
    ```

    **Change 4: Add Pydantic validation layer in the chat() endpoint:**

    After the crew kickoff result is obtained (after `reply = agent_result.get("message", "")` in both the short-circuit and manager paths), add a validation step before sanitize_reply():

    Add a new helper function before the chat() endpoint:
    ```python
    def _validate_crew_output(agent_result: dict, agent_name: str, language: str) -> str:
        """Validate crew output has a clean message field.

        Extracts the message from agent_result. If it looks like it contains
        delegation text or internal reasoning, attempts to extract the useful
        part. Falls back to a warm Gugu message if nothing usable.

        Args:
            agent_result: Dict returned from crew.kickoff() / parse_result()
            agent_name: Agent identifier for fallback selection
            language: Language code for fallback

        Returns:
            Clean message string ready for sanitize_reply()
        """
        message = agent_result.get("message", "")
        if not message or len(message.strip()) < 5:
            return _get_fallback(agent_name, language)

        # Quick check: if message starts with delegation text, try to extract useful part
        # (This catches cases where parse_result passed through unsanitized delegation text)
        for pattern in _DELEGATION_ARTIFACT_PATTERNS:
            if re.match(pattern, message.strip(), re.IGNORECASE):
                # Try to find actual citizen-facing content after the delegation text
                lines = message.strip().split("\n")
                citizen_lines = []
                past_delegation = False
                for line in lines:
                    stripped = line.strip()
                    if not stripped:
                        continue
                    is_delegation = any(
                        re.match(p, stripped, re.IGNORECASE)
                        for p in _DELEGATION_ARTIFACT_PATTERNS + _LLM_ARTIFACT_PATTERNS
                    )
                    if not is_delegation:
                        past_delegation = True
                        citizen_lines.append(line)
                    elif past_delegation:
                        # Delegation text AFTER citizen text — stop
                        break

                if citizen_lines:
                    return "\n".join(citizen_lines).strip()
                return _get_fallback(agent_name, language)

        return message
    ```

    In the chat() endpoint, add the validation call right before Step 3.5 (sanitize_reply):
    ```python
    # Step 3.25: Validate crew output — extract clean message
    reply = _validate_crew_output(agent_result, agent_name, detected_language)
    ```

    This replaces the raw `reply = agent_result.get("message", "")` that currently happens in both the short-circuit and manager paths. Move those lines to just set `raw_reply` for debug, and let _validate_crew_output set the actual reply.
  </action>
  <verify>
    ```
    OPENAI_API_KEY=dummy python -c "
    from src.api.v1.crew_server import sanitize_reply, _validate_crew_output, _DELEGATION_ARTIFACT_PATTERNS

    # Test delegation text is stripped
    result = sanitize_reply('As the Municipal Services Manager, here is the procedure for Gugu to follow: Step 1 - send OTP...', 'manager', 'en')
    assert 'Municipal Services Manager' not in result, f'Delegation leaked: {result}'

    # Test clean text passes through
    result = sanitize_reply('Hello! I am Gugu. How can I help you today?', 'manager', 'en')
    assert 'Gugu' in result, f'Clean text lost: {result}'

    # Test GBV emergency number safety
    result = sanitize_reply('I am sorry to hear that.', 'gbv_intake', 'en')
    assert '10111' in result, f'Missing emergency numbers: {result}'

    # Test _validate_crew_output
    result = _validate_crew_output({'message': 'As the Manager, I am delegating...\nHello, how can I help?'}, 'manager', 'en')
    assert 'Manager' not in result or 'help' in result, f'Validation failed: {result}'

    print('sanitize_reply + validation OK')
    "
    ```
  </verify>
  <done>
    sanitize_reply() strips all known delegation artifact patterns. GBV responses always include emergency numbers after sanitization. _validate_crew_output() provides pre-sanitization extraction of clean message from delegation-polluted output. All delegation patterns from research file are covered.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add delegation text filter to ManagerCrew.parse_result() and set verbose=False</name>
  <files>
    src/agents/crews/manager_crew.py
  </files>
  <action>
    **Change 1: Add delegation filtering patterns at module level (top of file, after imports):**

    ```python
    # Patterns that indicate internal delegation text (never citizen-facing)
    _DELEGATION_PATTERNS = [
        re.compile(r"^As the .{0,50} Manager", re.IGNORECASE),
        re.compile(r"^As the .{0,50} Specialist", re.IGNORECASE),
        re.compile(r"^Here is the (?:complete|correct).*procedure", re.IGNORECASE),
        re.compile(r"^For you,? Gugu", re.IGNORECASE),
        re.compile(r"^Dear Gugu", re.IGNORECASE),
        re.compile(r"^I am (?:now )?delegating", re.IGNORECASE),
        re.compile(r"^(?:Routing|Delegating) to", re.IGNORECASE),
        re.compile(r"^The manager has", re.IGNORECASE),
        re.compile(r"^Step \d+[:\.]", re.IGNORECASE),
        re.compile(r"^Procedure for", re.IGNORECASE),
        re.compile(r"^I have been assigned", re.IGNORECASE),
        re.compile(r"^(?:My|The) task is to", re.IGNORECASE),
    ]
    ```

    **Change 2: Update parse_result() to filter delegation text:**

    Replace the existing parse_result() with an enhanced version that strips delegation lines:

    ```python
    def parse_result(self, result) -> dict[str, Any]:
        """Extract clean citizen-facing message from CrewAI result.

        Strips "Final Answer:" prefix, delegation narration lines, and
        CrewAI artifacts. If delegation filtering removes everything,
        returns a warm Gugu fallback.
        """
        raw = str(result)

        # Strip "Final Answer:" prefix
        final = re.search(r"Final Answer:?\s*(.+)", raw, re.DOTALL | re.IGNORECASE)
        text = final.group(1).strip() if final else raw

        # Filter out delegation lines
        lines = text.split("\n")
        clean_lines = []
        for line in lines:
            stripped = line.strip()
            if not stripped:
                continue
            is_delegation = any(p.match(stripped) for p in _DELEGATION_PATTERNS)
            if not is_delegation:
                clean_lines.append(line)

        clean_message = "\n".join(clean_lines).strip()

        # If filtering removed everything, use warm fallback
        if not clean_message or len(clean_message) < 10:
            clean_message = (
                "I'm Gugu from SALGA Trust Engine. Something went wrong on my side "
                "-- please try again in a moment."
            )

        result_dict: dict[str, Any] = {
            "message": clean_message,
            "raw_output": raw,
        }

        # Include tracking number if present
        tracking_match = re.search(r"TKT-\d{8}-[A-F0-9]{6}", raw)
        if tracking_match:
            result_dict["tracking_number"] = tracking_match.group()

        return result_dict
    ```

    **Change 3: Set verbose=False in create_crew():**

    In the Crew() constructor (around line 198), change verbose=True to verbose=False:
    ```python
    crew = Crew(
        ...
        verbose=False,  # Changed from True — production mode (was testing mode)
    )
    ```

    IMPORTANT: Keep all other ManagerCrew code EXACTLY as-is. Do NOT add output_pydantic. Do NOT change Process.hierarchical. Do NOT modify the agent construction code.
  </action>
  <verify>
    ```
    OPENAI_API_KEY=dummy python -c "
    from src.agents.crews.manager_crew import ManagerCrew, _DELEGATION_PATTERNS

    # Verify delegation patterns are compiled regexes
    assert len(_DELEGATION_PATTERNS) >= 10, f'Only {len(_DELEGATION_PATTERNS)} patterns'

    # Test parse_result filters delegation
    class FakeResult:
        def __str__(self):
            return 'As the Municipal Services Manager, here is the procedure.\nStep 1: Send OTP.\nHello! How can I help you today?'

    mc = ManagerCrew.__new__(ManagerCrew)  # Skip __init__
    result = mc.parse_result(FakeResult())
    assert 'Municipal Services Manager' not in result['message'], f'Delegation leaked: {result[\"message\"]}'
    assert 'help you today' in result['message'], f'Clean content lost: {result[\"message\"]}'

    print('ManagerCrew parse_result delegation filtering OK')
    "
    ```
  </verify>
  <done>
    ManagerCrew.parse_result() strips all known delegation patterns before returning message. verbose=False in production Crew config. Delegation text like "As the Municipal Services Manager..." is filtered at this layer before it even reaches crew_server.py sanitize_reply(). Three-layer defense complete: prompt hardening (Plan 01) + ManagerCrew filter (this task) + sanitize_reply filter (Task 1).
  </done>
</task>

</tasks>

<verification>
1. Delegation text "As the Municipal Services Manager..." is filtered by ManagerCrew.parse_result()
2. Delegation text is also caught by sanitize_reply() _DELEGATION_ARTIFACT_PATTERNS (belt-and-suspenders)
3. GBV emergency numbers survive sanitization (safety check re-adds if stripped)
4. _validate_crew_output() catches delegation text in crew output before sanitization
5. ManagerCrew verbose=False (production mode)
6. Clean citizen-facing text passes through all layers unchanged
7. Warm Gugu fallback used when filtering removes all content
</verification>

<success_criteria>
Three-layer defense-in-depth complete: (1) prompt hardening prevents generation, (2) ManagerCrew.parse_result() filters at crew level, (3) crew_server.py sanitize_reply() filters at API level. Delegation text cannot reach citizens through any code path. GBV emergency numbers guaranteed.
</success_criteria>

<output>
After completion, create `.planning/phases/06.9.1-fix-agent-output-formatting-pydantic-models-auth-otp-tool-failures-and-system-prompt-engineering/06.9.1-03-SUMMARY.md`
</output>
