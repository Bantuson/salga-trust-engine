---
phase: 06.1-postgres-refactor-to-supabase-and-dashboard-separation
plan: 03
type: execute
wave: 2
depends_on: ["06.1-01"]
files_modified:
  - src/services/storage_service.py
  - src/api/v1/uploads.py
  - src/services/event_broadcaster.py
  - src/api/v1/events.py
autonomous: true

must_haves:
  truths:
    - "Media uploads go to Supabase Storage (not AWS S3)"
    - "GBV evidence stored in private 'gbv-evidence' bucket with SAPS-only RLS"
    - "General evidence stored in private 'evidence' bucket"
    - "Proof of residence documents stored in private 'documents' bucket"
    - "Supabase Storage provides signed URLs for secure file access (replacing S3 presigned URLs)"
    - "Dashboard real-time events use Supabase Realtime broadcast channels (not Redis Pub/Sub + SSE)"
    - "Each municipality has a dedicated realtime channel"
    - "Field-level Fernet encryption for GBV text data remains unchanged"
  artifacts:
    - path: "src/services/storage_service.py"
      provides: "Supabase Storage upload/download replacing S3"
      contains: "supabase_admin.storage"
    - path: "src/services/event_broadcaster.py"
      provides: "Supabase Realtime broadcast replacing Redis Pub/Sub"
      contains: "supabase.*channel"
  key_links:
    - from: "src/services/storage_service.py"
      to: "src/core/supabase.py"
      via: "supabase_admin for storage operations"
      pattern: "supabase_admin\\.storage"
    - from: "src/services/event_broadcaster.py"
      to: "src/core/supabase.py"
      via: "supabase_admin for realtime broadcast"
      pattern: "supabase_admin.*channel"
---

<objective>
Migrate storage from AWS S3 to Supabase Storage and migrate real-time events from Redis Pub/Sub + SSE to Supabase Realtime broadcast channels. Create private buckets with RLS policies for GBV evidence isolation.

Purpose: Consolidates infrastructure on Supabase Cloud. Storage migration brings RLS-integrated file access (no more presigned URL logic). Realtime migration enables WebSocket-based live updates with database-aware channels.

Output: StorageService uses Supabase Storage with GBV bucket isolation. EventBroadcaster uses Supabase Realtime channels.
</objective>

<execution_context>
@C:/Users/Bantu/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Bantu/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/STATE.md
@.planning/phases/06.1-postgres-refactor-to-supabase-and-dashboard-separation/06.1-CONTEXT.md
@.planning/phases/06.1-postgres-refactor-to-supabase-and-dashboard-separation/06.1-RESEARCH.md
@.planning/phases/06.1-postgres-refactor-to-supabase-and-dashboard-separation/06.1-01-SUMMARY.md
@src/services/storage_service.py
@src/services/event_broadcaster.py
@src/api/v1/uploads.py
@src/api/v1/events.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Migrate StorageService from AWS S3 to Supabase Storage</name>
  <files>
    src/services/storage_service.py
    src/api/v1/uploads.py
  </files>
  <action>
    **Step 1: Create Alembic migration for Supabase Storage buckets and RLS**
    Create a new migration that runs SQL to set up storage buckets and RLS policies:
    ```sql
    -- Create private buckets
    INSERT INTO storage.buckets (id, name, public) VALUES ('evidence', 'evidence', false);
    INSERT INTO storage.buckets (id, name, public) VALUES ('documents', 'documents', false);
    INSERT INTO storage.buckets (id, name, public) VALUES ('gbv-evidence', 'gbv-evidence', false);

    -- Evidence bucket: authenticated users can upload/read their own tenant's files
    CREATE POLICY "Authenticated users upload evidence"
    ON storage.objects FOR INSERT TO authenticated
    WITH CHECK (
      bucket_id = 'evidence'
      AND (storage.foldername(name))[1] = (SELECT (auth.jwt() -> 'app_metadata' ->> 'tenant_id'))
    );

    CREATE POLICY "Authenticated users read evidence"
    ON storage.objects FOR SELECT TO authenticated
    USING (
      bucket_id = 'evidence'
      AND (storage.foldername(name))[1] = (SELECT (auth.jwt() -> 'app_metadata' ->> 'tenant_id'))
    );

    -- Documents bucket: same pattern
    CREATE POLICY "Authenticated users upload documents"
    ON storage.objects FOR INSERT TO authenticated
    WITH CHECK (
      bucket_id = 'documents'
      AND (storage.foldername(name))[1] = (SELECT (auth.jwt() -> 'app_metadata' ->> 'tenant_id'))
    );

    CREATE POLICY "Authenticated users read documents"
    ON storage.objects FOR SELECT TO authenticated
    USING (
      bucket_id = 'documents'
      AND (storage.foldername(name))[1] = (SELECT (auth.jwt() -> 'app_metadata' ->> 'tenant_id'))
    );

    -- GBV evidence bucket: SAPS_LIAISON and ADMIN ONLY (SEC-05 firewall)
    CREATE POLICY "SAPS liaisons read GBV evidence"
    ON storage.objects FOR SELECT TO authenticated
    USING (
      bucket_id = 'gbv-evidence'
      AND (SELECT (auth.jwt() -> 'app_metadata' ->> 'role')) IN ('saps_liaison', 'admin')
      AND (storage.foldername(name))[1] = (SELECT (auth.jwt() -> 'app_metadata' ->> 'tenant_id'))
    );

    CREATE POLICY "Authorized staff upload GBV evidence"
    ON storage.objects FOR INSERT TO authenticated
    WITH CHECK (
      bucket_id = 'gbv-evidence'
      AND (SELECT (auth.jwt() -> 'app_metadata' ->> 'role')) IN ('saps_liaison', 'admin', 'manager')
    );
    ```
    Note: Bucket creation via SQL requires Supabase. Wrap in try/except for development environments.

    **Step 2: Rewrite src/services/storage_service.py**
    Replace the entire S3-based StorageService with Supabase Storage:

    - Remove: boto3 import, AWS credential checks, S3 client, presigned URL generation
    - Add: import from src.core.supabase import get_supabase_admin

    - generate_upload_url(purpose, tenant_id, file_id, filename, content_type) -> dict:
      Supabase Storage doesn't use presigned POST like S3. Instead:
      - Return the storage path pattern: {tenant_id}/{file_id}/{filename}
      - Return the bucket name based on purpose ("evidence", "documents", "gbv-evidence")
      - The frontend will use supabase.storage.from(bucket).upload(path, file) directly
      - For server-side uploads (Twilio media), use supabase_admin.storage.from_(bucket).upload(path, content)

    - upload_file(bucket, path, content, content_type) -> dict:
      Server-side upload using admin client (for WhatsApp media download+upload)
      - supabase_admin.storage.from_(bucket).upload(path, content, {"content-type": content_type, "upsert": "false"})
      - Return {"bucket": bucket, "path": path}

    - get_signed_url(bucket, path, expiry=3600) -> str:
      - supabase_admin.storage.from_(bucket).create_signed_url(path, expiry)
      - Return signed URL string

    - download_and_upload_media(media_url, media_content_type, ticket_id, tenant_id, auth_credentials) -> dict:
      Same logic as before but upload to Supabase Storage instead of S3.
      - Download from Twilio via httpx
      - Determine bucket: "gbv-evidence" if ticket is sensitive, else "evidence"
      - Upload via supabase_admin.storage.from_(bucket).upload(path, content)
      - Return {"bucket": bucket, "path": path, "file_id": file_id, "content_type": type, "file_size": size}

    - Keep StorageServiceError exception class
    - Add graceful degradation: if supabase_admin is None (no config), raise StorageServiceError

    **Step 3: Update src/api/v1/uploads.py**
    - Update presigned upload endpoint to return Supabase storage path + bucket instead of S3 presigned POST
    - The response changes from {url, fields, file_id} to {bucket, path, file_id}
    - Frontend will need to use Supabase JS SDK storage.from(bucket).upload(path, file) instead of POST to S3 URL
  </action>
  <verify>
    - `python -c "from src.services.storage_service import StorageService; print('OK')"` succeeds
    - `python -c "from src.services.storage_service import StorageService; s = StorageService(); print(type(s))"` succeeds
    - No boto3 import in storage_service.py: `grep -c "boto3" src/services/storage_service.py` returns 0
    - `alembic heads` shows new storage bucket migration
  </verify>
  <done>
    StorageService uses Supabase Storage for all file operations. Three private buckets created (evidence, documents, gbv-evidence) with RLS policies. GBV bucket restricted to SAPS_LIAISON + ADMIN only. S3 dependency removed from storage service.
  </done>
</task>

<task type="auto">
  <name>Task 2: Migrate EventBroadcaster from Redis Pub/Sub to Supabase Realtime</name>
  <files>
    src/services/event_broadcaster.py
    src/api/v1/events.py
  </files>
  <action>
    **Step 1: Rewrite src/services/event_broadcaster.py**
    Replace Redis Pub/Sub with Supabase Realtime broadcast channels:

    - Remove: redis.asyncio import, Redis client, pubsub, Redis connection management
    - Add: import from src.core.supabase

    - EventBroadcaster class:
      - __init__: no Redis client needed
      - publish(municipality_id: str, event: dict) -> None:
        Use Supabase admin client to broadcast on channel `municipality:{municipality_id}`
        ```python
        channel = supabase_admin.realtime.channel(f"municipality:{municipality_id}")
        await channel.send_broadcast("ticket_event", event)
        ```
        Note: supabase-py realtime API may vary. Use the pattern from research:
        - If supabase-py does not support realtime broadcast from Python, fall back to PostgreSQL pg_notify via direct SQL execution
        - Create a PostgreSQL trigger function that broadcasts ticket changes:
          ```sql
          CREATE OR REPLACE FUNCTION notify_ticket_update() RETURNS TRIGGER AS $$
          BEGIN
            PERFORM pg_notify('ticket_updates', json_build_object(
              'type', TG_OP,
              'ticket_id', NEW.id::text,
              'status', NEW.status,
              'municipality_id', NEW.tenant_id::text
            )::text);
            RETURN NEW;
          END;
          $$ LANGUAGE plpgsql;

          CREATE TRIGGER ticket_update_notify
          AFTER INSERT OR UPDATE ON tickets
          FOR EACH ROW EXECUTE FUNCTION notify_ticket_update();
          ```
        - The backend publish() method can also use direct pg_notify for immediate events
        - Supabase Realtime will automatically pick up pg_notify and broadcast to WebSocket subscribers

      - subscribe method: REMOVE entirely â€” frontend will subscribe via Supabase JS client directly
        The SSE endpoint becomes unnecessary since Supabase Realtime uses WebSocket natively

      - close(): no-op (no Redis connection to close)

    **Step 2: Create Alembic migration for ticket update trigger**
    Create migration that adds the PostgreSQL trigger function and trigger on tickets table.
    This enables Supabase Realtime to broadcast ticket changes automatically.

    **Step 3: Simplify src/api/v1/events.py**
    The existing SSE endpoint used Redis Pub/Sub subscribe + Server-Sent Events.
    With Supabase Realtime, the frontend subscribes directly via WebSocket (Supabase JS SDK).
    - Keep the events router but mark the SSE endpoint as deprecated
    - Add a comment explaining the migration to Supabase Realtime
    - The SSE endpoint can remain as a fallback but is no longer the primary realtime mechanism
    - Remove Redis dependency from the events module
  </action>
  <verify>
    - `python -c "from src.services.event_broadcaster import EventBroadcaster; print('OK')"` succeeds
    - No redis import in event_broadcaster.py: `grep -c "redis" src/services/event_broadcaster.py` returns 0
    - `alembic heads` shows new trigger migration
    - `python -c "from src.api.v1.events import router; print('OK')"` succeeds
  </verify>
  <done>
    EventBroadcaster uses Supabase Realtime (via pg_notify triggers). PostgreSQL trigger on tickets table broadcasts all changes. SSE endpoint deprecated in favor of WebSocket. Redis dependency removed from event broadcasting.
  </done>
</task>

</tasks>

<verification>
1. StorageService imports and initializes without boto3
2. Three storage buckets defined with correct RLS (GBV restricted to SAPS_LIAISON)
3. EventBroadcaster has no Redis dependency
4. PostgreSQL trigger migration exists for ticket_updates
5. Field-level Fernet encryption unchanged (GBV text data still encrypted)
6. Existing unit tests that don't use storage/events still pass
</verification>

<success_criteria>
- StorageService uses supabase_admin.storage for all operations
- Three private buckets: evidence, documents, gbv-evidence
- GBV bucket RLS restricts to saps_liaison + admin roles
- EventBroadcaster uses pg_notify for Supabase Realtime integration
- Ticket update trigger created via Alembic migration
- SSE endpoint deprecated (frontend will use Supabase Realtime WebSocket)
- No new S3 or Redis dependencies introduced
</success_criteria>

<output>
After completion, create `.planning/phases/06.1-postgres-refactor-to-supabase-and-dashboard-separation/06.1-03-SUMMARY.md`
</output>
