---
phase: 06.8-gugu-persona-email-otp-fix
plan: 03
type: execute
wave: 2
depends_on:
  - 01
files_modified:
  - src/api/v1/crew_server.py
  - src/agents/crews/auth_crew.py
  - src/agents/crews/municipal_crew.py
  - src/agents/crews/gbv_crew.py
autonomous: true
requirements:
  - AI-05
  - AI-07

must_haves:
  truths:
    - "Citizens never see raw LLM reasoning, tool call JSON, or CrewAI internal artifacts in replies"
    - "Error responses are user-friendly messages, never stack traces or internal exception details"
    - "Response sanitizer strips Thought:/Action:/Observation: markers, JSON blobs, and system prompts"
    - "Each agent type has a typed Pydantic response model that enforces clean output structure"
    - "Fallback responses are warm and Gugu-voiced when sanitization can't extract a clean reply"
    - "GBV error fallbacks include emergency numbers (10111, 0800 150 150)"
    - "Debug dict still contains full raw output for Streamlit dashboard inspection (developer-only)"
  artifacts:
    - path: "src/api/v1/crew_server.py"
      provides: "sanitize_reply() function and Pydantic agent response models"
      contains: "sanitize_reply"
    - path: "src/agents/crews/auth_crew.py"
      provides: "Cleaned kickoff() return with sanitized message field"
      contains: "sanitize"
    - path: "src/agents/crews/municipal_crew.py"
      provides: "Cleaned kickoff() return with sanitized message field"
      contains: "sanitize"
    - path: "src/agents/crews/gbv_crew.py"
      provides: "Cleaned kickoff() return with sanitized message field"
      contains: "sanitize"
  key_links:
    - from: "src/api/v1/crew_server.py"
      to: "src/agents/crews/auth_crew.py"
      via: "auth_result['message'] is already sanitized before reaching ChatResponse"
      pattern: "sanitize_reply"
---

<objective>
Add response sanitization layer so citizens never see raw LLM reasoning, tool call JSON, CrewAI artifacts, or internal error details. Create a sanitize_reply() utility that strips non-human output, and add Pydantic models for typed agent responses. Ensure all error paths return warm, Gugu-voiced fallback messages.

Purpose: The current crew kickoff() methods return raw LLM output that may contain "Thought: I need to call...", JSON blobs from tool results, or Python exceptions. Citizens should only see clean, conversational text from Gugu. Developer debug info stays in the debug dict for Streamlit.

Output: sanitize_reply() function in crew_server.py, sanitized message fields in all three crew kickoff() methods, and warm fallback messages for all error paths.
</objective>

<execution_context>
@C:/Users/Bantu/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Bantu/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06.8-gugu-persona-email-otp-fix/06.8-RESEARCH.md

@src/api/v1/crew_server.py
@src/agents/crews/auth_crew.py
@src/agents/crews/municipal_crew.py
@src/agents/crews/gbv_crew.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create sanitize_reply() utility and warm fallback messages</name>
  <files>
    src/api/v1/crew_server.py
  </files>
  <action>
Add a `sanitize_reply()` function to `src/api/v1/crew_server.py` (above the endpoints section) that strips non-human content from agent responses:

```python
import re

# ---------------------------------------------------------------------------
# Response sanitization — hide LLM internals from citizens
# ---------------------------------------------------------------------------

# Patterns that indicate LLM reasoning artifacts (not citizen-facing text)
_LLM_ARTIFACT_PATTERNS = [
    r"^Thought:.*$",          # CrewAI verbose reasoning
    r"^Action:.*$",           # CrewAI tool call declarations
    r"^Action Input:.*$",     # CrewAI tool input
    r"^Observation:.*$",      # CrewAI tool output markers
    r"^I need to .*$",        # LLM self-talk
    r"^Let me .*$",           # LLM self-talk
    r"^I'll .*call.*$",       # LLM tool-calling narration
    r"^I should .*$",         # LLM planning
    r"^Now I .*$",            # LLM sequencing
    r"^Based on the (?:tool|function) (?:result|output).*$",  # Tool result narration
    r"^The (?:tool|function) returned.*$",
    r"^Final Answer:?\s*",    # CrewAI final answer marker (strip prefix, keep content after it)
]

# Warm fallbacks when sanitization leaves nothing usable
_FALLBACK_REPLIES = {
    "auth_agent": {
        "en": "I'm Gugu from SALGA Trust Engine. I'm having a moment — could you please repeat that?",
        "zu": "NginguGugu we-SALGA Trust Engine. Ngicela uphinde — angizwanga kahle.",
        "af": "Ek is Gugu van SALGA Trust Engine. Ek het 'n oomblik — kan jy asseblief herhaal?",
    },
    "municipal_intake": {
        "en": "I'm Gugu from SALGA Trust Engine. Sorry, I didn't quite catch that — could you describe your issue again?",
        "zu": "NginguGugu we-SALGA Trust Engine. Ngiyaxolisa, angizwanga kahle — ungachaza inkinga yakho futhi?",
        "af": "Ek is Gugu van SALGA Trust Engine. Jammer, ek het dit nie gevang nie — kan jy jou probleem weer beskryf?",
    },
    "gbv_intake": {
        "en": "I'm here to help you. If you are in immediate danger, please call 10111 or the GBV Command Centre at 0800 150 150. Can you tell me what happened?",
        "zu": "Ngilapha ukukusiza. Uma usengozini, shayela i-10111 noma i-GBV Command Centre ku-0800 150 150. Ungangitshela ukuthi kwenzekeni?",
        "af": "Ek is hier om jou te help. As jy in onmiddellike gevaar is, skakel 10111 of die GBV Command Centre by 0800 150 150. Kan jy my vertel wat gebeur het?",
    },
    "error": {
        "en": "I'm Gugu from SALGA Trust Engine. Something went wrong on my side — please try again in a moment.",
        "zu": "NginguGugu we-SALGA Trust Engine. Kunenkinga ngasohlangothini lwami — ngicela uzame futhi ngemva kwesikhashana.",
        "af": "Ek is Gugu van SALGA Trust Engine. Iets het verkeerd gegaan aan my kant — probeer asseblief weer oor 'n oomblik.",
    },
}


def sanitize_reply(
    raw: str,
    agent_name: str = "auth_agent",
    language: str = "en",
) -> str:
    """Strip LLM reasoning artifacts from agent output for citizen display.

    Removes CrewAI verbose markers (Thought/Action/Observation), LLM self-talk,
    embedded JSON blobs, and tool result narration. Returns only the clean,
    citizen-facing message text.

    If sanitization strips everything (empty result), returns a warm Gugu-voiced
    fallback appropriate to the agent type and language.

    Args:
        raw: Raw agent output string (may contain LLM artifacts).
        agent_name: Agent type for fallback selection ("auth_agent", "municipal_intake", "gbv_intake").
        language: Language code for fallback ("en", "zu", "af").

    Returns:
        Clean, citizen-facing reply text.
    """
    if not raw or not raw.strip():
        return _get_fallback(agent_name, language)

    text = raw.strip()

    # 1. If "Final Answer:" marker exists, take everything AFTER it
    final_match = re.search(r"Final Answer:?\s*(.+)", text, re.DOTALL | re.IGNORECASE)
    if final_match:
        text = final_match.group(1).strip()

    # 2. Remove JSON blobs (tool call results embedded in text)
    text = re.sub(r'\{[^{}]*"(?:tracking_number|error|id|status)"[^{}]*\}', '', text)

    # 3. Remove LLM artifact lines
    lines = text.split("\n")
    clean_lines = []
    for line in lines:
        stripped = line.strip()
        if not stripped:
            continue
        # Skip lines matching artifact patterns
        skip = False
        for pattern in _LLM_ARTIFACT_PATTERNS:
            if re.match(pattern, stripped, re.IGNORECASE):
                # Special case: "Final Answer:" prefix — keep content after it
                if pattern == r"^Final Answer:?\s*":
                    stripped = re.sub(r"^Final Answer:?\s*", "", stripped, flags=re.IGNORECASE)
                    if stripped:
                        clean_lines.append(stripped)
                skip = True
                break
        if not skip:
            clean_lines.append(line)

    text = "\n".join(clean_lines).strip()

    # 4. Remove any remaining raw Python exception traces
    text = re.sub(r"Traceback \(most recent call last\):.*?(?=\n\n|\Z)", "", text, flags=re.DOTALL)
    text = re.sub(r"(?:Error|Exception):.*?(?=\n\n|\Z)", "", text, flags=re.DOTALL)

    # 5. If nothing useful remains, use warm fallback
    if not text or len(text) < 10:
        return _get_fallback(agent_name, language)

    return text.strip()


def _get_fallback(agent_name: str, language: str) -> str:
    """Get a warm Gugu-voiced fallback message for the given agent and language."""
    lang = language if language in ("en", "zu", "af") else "en"
    agent = agent_name if agent_name in _FALLBACK_REPLIES else "error"
    return _FALLBACK_REPLIES[agent][lang]
```

Then update the existing error handler in the `chat()` endpoint (the `except Exception` block around line 572) to use the fallback:

Replace the current error reply logic:
```python
if any(keyword in error_str.lower() for keyword in (...)):
    reply = "DeepSeek API unavailable, please retry"
else:
    reply = "An unexpected error occurred. Please try again."
```

With:
```python
if any(keyword in error_str.lower() for keyword in ("deepseek", "api", "litellm", "openai", "timeout", "connection", "rate limit")):
    reply = _get_fallback("error", detected_language if 'detected_language' in dir() else request.language)
else:
    reply = _get_fallback("error", detected_language if 'detected_language' in dir() else request.language)
```

Note: After Plan 02's changes, `detected_language` will be available. Use a safe fallback to `request.language` if Plan 02 hasn't been applied yet.

Finally, apply `sanitize_reply()` to the reply BEFORE saving to conversation history (Step 4) and returning the response (Step 5). Add one line after the agent routing block (Step 3) exits:

```python
# Sanitize reply — strip LLM artifacts for citizen-facing output
reply = sanitize_reply(reply, agent_name=agent_name, language=detected_language if 'detected_language' in dir() else request.language)
```

CRITICAL: The raw unsanitized output should still be available in the `debug` dict's `agent_result` field so the Streamlit dashboard can inspect it for development.
  </action>
  <verify>
Run `python -c "from src.api.v1.crew_server import sanitize_reply, _get_fallback; print(sanitize_reply('Thought: I need to call tool\nFinal Answer: Hi! I am Gugu.', 'auth_agent', 'en'))"` — should output "Hi! I am Gugu." (no "Thought:" line).

Run `python -c "from src.api.v1.crew_server import sanitize_reply; print(sanitize_reply('', 'auth_agent', 'en'))"` — should output a warm Gugu fallback message.

Run `python -c "from src.api.v1.crew_server import sanitize_reply; print(sanitize_reply('{\"tracking_number\": \"TKT-123\", \"status\": \"open\"} Your report has been logged.', 'municipal_intake', 'en'))"` — should output "Your report has been logged." (JSON blob stripped).

Grep for "sanitize_reply" in crew_server.py — must find the function definition AND at least one call site.
  </verify>
  <done>
sanitize_reply() function added to crew_server.py with: LLM artifact pattern stripping, JSON blob removal, Final Answer extraction, exception trace removal, and warm Gugu-voiced trilingual fallbacks for all agent types. All error paths use _get_fallback() instead of generic English messages. Reply is sanitized before saving to history and returning to citizen. Raw output preserved in debug dict for Streamlit.
  </done>
</task>

<task type="auto">
  <name>Task 2: Sanitize crew kickoff() outputs in all three crews</name>
  <files>
    src/agents/crews/auth_crew.py
    src/agents/crews/municipal_crew.py
    src/agents/crews/gbv_crew.py
  </files>
  <action>
Add lightweight output cleaning to each crew's `kickoff()` method so the `message` field in the returned dict is already partially cleaned before it reaches crew_server.py. This is defense-in-depth — crew_server.py's sanitize_reply() is the primary filter, but crews should also do basic cleanup.

**auth_crew.py** — In the `kickoff()` method, after extracting `auth_result`:

1. In the Pydantic branch (line ~159-161, `if hasattr(result, "pydantic") and result.pydantic`): The `auth_result.message` comes from the Pydantic model, which is already cleaner than raw output. BUT it may still contain LLM artifacts if the model fills the `message` field with reasoning text. Add a basic strip:
   ```python
   result_dict = auth_result.model_dump()
   # Strip "Final Answer:" prefix if LLM included it in the message field
   msg = result_dict.get("message", "")
   if msg and "Final Answer:" in msg:
       msg = msg.split("Final Answer:", 1)[-1].strip()
       result_dict["message"] = msg
   return result_dict
   ```

2. In the fallback branch (line ~164-169): The `str(result)` is raw LLM output and the most likely source of artifacts. Add basic extraction:
   ```python
   raw = str(result)
   # Try to extract just the final answer portion
   import re
   final = re.search(r"Final Answer:?\s*(.+)", raw, re.DOTALL | re.IGNORECASE)
   message = final.group(1).strip() if final else raw
   return {
       "authenticated": False,
       "session_status": "failed",
       "message": message,
       "raw_output": raw,  # Keep raw for debug
       "error": None,
   }
   ```

3. In the exception handler (line ~171-177): Keep the existing user-friendly error message as-is (it's already clean).

**municipal_crew.py** — In the `kickoff()` method:

1. After `raw = str(result)` (line ~146): Add the same Final Answer extraction:
   ```python
   import re
   final = re.search(r"Final Answer:?\s*(.+)", raw, re.DOTALL | re.IGNORECASE)
   clean_message = final.group(1).strip() if final else raw
   ```

2. When returning results, use `clean_message` as the `message` value instead of `raw`:
   - In the JSON match branch: keep `ticket_dict["message"] = clean_message` (not raw)
   - In the tracking_match branch: use `"message": clean_message`
   - In the fallback branch: use `"message": clean_message`

3. Add a `"raw_output": raw` field to all return dicts for debug purposes.

**gbv_crew.py** — Same pattern as municipal_crew.py:

1. After `raw = str(result)` (line ~169): Add Final Answer extraction.
2. Use `clean_message` in all return dict `message` fields.
3. Add `"raw_output": raw` for debug.
4. CRITICAL: GBV error fallback MUST include emergency numbers:
   ```python
   except Exception as e:
       return {
           "error": str(e),
           "message": "I'm here to help. If you are in immediate danger, call 10111 or the GBV Command Centre at 0800 150 150.",
       }
   ```

CONSTRAINTS:
- Do NOT change crew wiring (Agent, Task, Crew constructors).
- Do NOT change the kickoff input parameters.
- Do NOT add new dependencies.
- The `re` module is already imported in municipal_crew.py and gbv_crew.py. Add it to auth_crew.py if not present.
  </action>
  <verify>
Run `python -c "from src.agents.crews.auth_crew import AuthCrew; print('Import OK')"` — must succeed.
Run `python -c "from src.agents.crews.municipal_crew import MunicipalCrew; print('Import OK')"` — must succeed.
Run `python -c "from src.agents.crews.gbv_crew import GBVCrew; print('Import OK')"` — must succeed.

Grep for "raw_output" in all three crew files — must appear in return dicts (debug field preserved).
Grep for "Final Answer" in all three crew files — must appear in extraction logic.
Grep for "10111" in gbv_crew.py — must still be present (emergency number in error fallback).
  </verify>
  <done>
All three crew kickoff() methods extract "Final Answer:" content from raw LLM output, strip the prefix, and use cleaned text as the message field. Raw output preserved in raw_output field for debug. Error fallbacks are user-friendly — GBV error includes emergency numbers. No crew wiring changes, no new dependencies.
  </done>
</task>

</tasks>

<verification>
1. sanitize_reply() function exists in crew_server.py and handles: empty input, Final Answer extraction, JSON blob removal, LLM artifact stripping, exception trace removal
2. Warm Gugu-voiced fallbacks exist for all agent types in all 3 languages
3. GBV fallback includes emergency numbers (10111, 0800 150 150)
4. All three crew kickoff() methods strip "Final Answer:" prefix from message field
5. Raw output preserved in debug/raw_output for Streamlit inspection
6. Error paths in crew_server.py use warm fallbacks instead of generic English messages
7. All Python imports succeed without errors
</verification>

<success_criteria>
- Citizens never see Thought:/Action:/Observation: markers in replies
- Citizens never see JSON blobs or tool result dicts in replies
- Citizens never see Python stack traces or internal error messages
- Error responses are warm and Gugu-voiced in the citizen's language
- GBV errors always include emergency numbers
- Developers can still see full raw output in debug dict via Streamlit
</success_criteria>

<output>
After completion, create `.planning/phases/06.8-gugu-persona-email-otp-fix/06.8-03-SUMMARY.md`
</output>
