# Phase 06.7: Municipal Intake Agent Testing - Research

**Researched:** 2026-02-17
**Domain:** CrewAI agentic LLM integration (DeepSeek), Streamlit testing dashboard, auth agent, phone detection, FastAPI API-first
**Confidence:** HIGH

---

<user_constraints>
## User Constraints (from CONTEXT.md)

### Locked Decisions

#### Auth Agent Conversation Flow
- Dual registration option: auth agent asks "Register with phone or email?" and adapts flow based on user choice
- Phone registration: collect phone -> send OTP -> verify -> collect name + email -> proof of residence upload (OCR) -> municipality assignment
- Email registration: collect email -> send OTP -> verify -> collect name + phone -> proof of residence upload (OCR) -> municipality assignment
- Proof of residence is REQUIRED before municipality assignment (strict verification, not deferred to profile)
- Returning users with expired sessions re-authenticate via OTP only (no password flow)
- GBV reports use same auth as municipal reports — sensitivity is handled at intake agent level, not auth agent level
- Auth agent must create Supabase Auth account and populate user_metadata (role, tenant_id, residence_verified)

#### Phone Detection & Session Management
- Detection triggers on session start only — if active session exists, skip detection and go straight to intake agent
- Phone-only lookup for initial detection (email lookup happens inside auth agent if needed)
- Minimal context passed to auth agent: user_exists (bool), session_status (active/expired/none), user_id (if exists)
- Auth agent fetches additional user details from DB if needed (not detection system's job)
- 24hr session expiry via database timestamp: session table with created_at, detection system compares current time vs created_at + 24hr
- Expired sessions get status='expired' and require OTP re-authentication

#### Streamlit Chat Dashboard
- WhatsApp-style layout: message bubbles (user on right, agent on left), scrolling conversation, text input at bottom
- Agent labels hidden from main chat view (mimics real WhatsApp experience) — agent identification in separate debug panel/log
- Rich test controls in sidebar: phone number input, Reset conversation button, Language selector (EN/ZU/AF), Municipality picker, Session override (force expired/new), Scenario presets (municipal/GBV), Agent state viewer
- Connects to live Supabase database — test with real data, see results in existing dashboards
- Debug panel shows: current agent, conversation state, session info, last API response

#### DeepSeek & CrewAI Configuration
- Model: DeepSeek V3.2 specifically (model name: `deepseek-chat` on DeepSeek API)
- API key located in root .env file (DEEPSEEK_API_KEY) — NEVER read or display this file
- OpenAI-compatible endpoint integration: CrewAI LLM config with DeepSeek's base_url + api_key
- Persistent crew server: CrewAI crew runs as long-lived process, Streamlit connects via HTTP
- No fallback model: if DeepSeek API is unavailable, show clear error in Streamlit chat ('DeepSeek API unavailable, please retry')
- No retry logic for API failures — fail fast and clear

### Claude's Discretion
- Exact CrewAI agent/task/tool structure for auth agent and intake agent
- Session table schema design
- Streamlit component layout and styling
- API endpoint URL structure and request/response schemas
- Error message wording and UX copy
- Debug panel implementation details

### Deferred Ideas (OUT OF SCOPE)
None — discussion stayed within phase scope
</user_constraints>

---

## Summary

This phase connects the existing Phase 2 CrewAI architecture to a real LLM (DeepSeek V3.2) and provides a developer testing interface. The codebase already has `MunicipalCrew` and `GBVCrew` classes with placeholder LLM wiring (`llm=self.llm_model` passed as a string), the `IntakeFlow` orchestrator, Redis-backed `ConversationManager`, Supabase Auth with phone OTP, and the `WhatsAppSession` model with 24hr expiry — all of which Phase 06.7 builds on directly.

The key new elements are: (1) an `AuthCrew` using CrewAI `LLM` object pointed at DeepSeek via OpenAI-compatible endpoint, (2) a deterministic phone detection system (not an agent) that looks up `WhatsAppSession`, (3) a crew server exposing HTTP endpoints that Streamlit can call, and (4) a Streamlit developer dashboard with WhatsApp-style chat UI and debug sidebar. The existing `WhatsAppSession` model already implements 24hr expiry exactly as the context requires — reuse it directly.

**Primary recommendation:** Wire `crewai.LLM(model="deepseek/deepseek-chat", base_url="https://api.deepseek.com/v1", api_key=settings.DEEPSEEK_API_KEY)` and pass it to all crew agents. Build the crew server as a standalone FastAPI app (separate from main.py). Streamlit calls the crew server's HTTP endpoints — no shared in-process state.

---

## Standard Stack

### Core
| Library | Version | Purpose | Why Standard |
|---------|---------|---------|--------------|
| crewai | 1.8.1 (already installed) | Agent/task/crew/flow orchestration | Already in use, Phase 2 crews built on it |
| streamlit | 1.53.1 (already installed) | Developer test dashboard UI | Installed, locked decision |
| httpx | >=0.28.0 (already in pyproject) | Streamlit → crew server HTTP calls | Already in deps, async-friendly |
| fastapi | 0.128.0 (already installed) | Crew server HTTP API | Already in use throughout codebase |
| supabase | >=2.27.3 (already installed) | Auth OTP, user_metadata, DB queries | Already integrated |
| pydantic-settings | 2.7.0 (already installed) | DEEPSEEK_API_KEY env var loading | Already in use via Settings class |

### Supporting
| Library | Version | Purpose | When to Use |
|---------|---------|---------|-------------|
| crewai LLM class | (part of crewai 1.8.1) | Wraps LiteLLM for DeepSeek | Use instead of passing model string to Agent |
| redis | 5.2.0 (already installed) | Conversation state for auth agent multi-turn | Reuse existing ConversationManager |
| sqlalchemy | 2.0.36 (already installed) | Session table CRUD | Reuse existing sync engine pattern from ticket_tool.py |

### Alternatives Considered
| Instead of | Could Use | Tradeoff |
|------------|-----------|----------|
| Standalone FastAPI crew server | In-process crew in Streamlit | In-process is simpler but couples Streamlit to CrewAI; HTTP separation enables future replacement |
| `crewai.LLM` object | Passing model string to `Agent(llm=...)` | LLM object gives explicit base_url control; string requires env var hacks |
| Reuse WhatsAppSession table | New session table | WhatsAppSession already has phone, user_id, tenant_id, expires_at — exactly what's needed |

**Installation:** No new installs needed. crewai 1.8.1, streamlit 1.53.1, and httpx are already installed.

---

## Architecture Patterns

### Recommended Project Structure

```
src/
├── agents/
│   ├── crews/
│   │   ├── municipal_crew.py     # EXISTS — update llm= to use LLM object
│   │   ├── gbv_crew.py           # EXISTS — update llm= to use LLM object
│   │   └── auth_crew.py          # NEW — auth agent with dual registration flow
│   ├── flows/
│   │   ├── intake_flow.py        # EXISTS — update llm_model param
│   │   └── state.py              # EXISTS — may need auth_state addition
│   ├── config/
│   │   ├── agents.yaml           # EXISTS — add auth_agent entry
│   │   └── tasks.yaml            # EXISTS — add auth tasks
│   └── tools/
│       ├── ticket_tool.py        # EXISTS — no changes needed
│       ├── saps_tool.py          # EXISTS — no changes needed
│       └── auth_tool.py          # NEW — Supabase Auth OTP + user creation tool
├── api/v1/
│   └── intake_agent.py           # NEW — crew server HTTP endpoints
└── core/
    └── config.py                 # UPDATE — add DEEPSEEK_API_KEY field

streamlit_dashboard/
├── app.py                        # NEW — main Streamlit entry point
├── components/
│   ├── chat.py                   # NEW — WhatsApp-style chat bubbles
│   ├── sidebar.py                # NEW — test controls sidebar
│   └── debug_panel.py            # NEW — agent state debug panel
└── api_client.py                 # NEW — httpx calls to crew server
```

### Pattern 1: DeepSeek LLM via CrewAI LLM object

**What:** Use `crewai.LLM` (backed by LiteLLM) with explicit `base_url` and `api_key` for DeepSeek V3.2.

**When to use:** Everywhere a CrewAI `Agent` needs an LLM. Replace the current `llm=self.llm_model` (string) with a `LLM` object.

**Example:**
```python
# Source: crewai docs + DeepSeek API docs (https://api-docs.deepseek.com/)
from crewai import LLM
from src.core.config import settings

def get_deepseek_llm() -> LLM:
    """Factory for DeepSeek V3.2 LLM via OpenAI-compatible endpoint."""
    return LLM(
        model="deepseek/deepseek-chat",  # LiteLLM format: provider/model
        base_url="https://api.deepseek.com/v1",
        api_key=settings.DEEPSEEK_API_KEY,
        temperature=0.7,
        max_tokens=2048,
    )
```

**CRITICAL NOTE:** LiteLLM (used by CrewAI internally) requires the model string in format `provider/model-name` when using a custom base_url. Use `"deepseek/deepseek-chat"` — NOT just `"deepseek-chat"`. The `OPENAI_API_KEY` env var may still be validated by CrewAI internally; set `OPENAI_API_KEY="dummy"` in test environments to avoid auth errors (documented CrewAI known issue).

### Pattern 2: Auth Agent as CrewAI Crew

**What:** AuthCrew follows the same MunicipalCrew pattern — single agent, single multi-step task, Pydantic output.

**When to use:** Auth is a conversational multi-turn flow — exactly what CrewAI agents handle well.

**Example:**
```python
# Pattern mirrors src/agents/crews/municipal_crew.py
from crewai import Agent, Crew, Process, Task
from src.agents.tools.auth_tool import (
    send_otp,
    verify_otp,
    create_supabase_user,
    lookup_user_by_email,
    upload_proof_of_residence
)

class AuthCrew:
    def __init__(self, language: str = "en"):
        self.language = language
        self.llm = get_deepseek_llm()

    def create_crew(self, context: dict) -> Crew:
        # context = {user_exists, session_status, user_id, phone}
        agent = Agent(
            role="Authentication Specialist",
            goal=f"Register or authenticate citizen in {self.language}",
            backstory=AUTH_PROMPTS[self.language],
            tools=[send_otp, verify_otp, create_supabase_user,
                   lookup_user_by_email, upload_proof_of_residence],
            llm=self.llm,
            allow_delegation=False,
            max_iter=15,  # Auth needs more turns than intake
            verbose=False
        )
        task = Task(
            description=AUTH_TASK_TEMPLATE.format(**context, language=self.language),
            expected_output="Authenticated user with session token or error message",
            agent=agent,
            output_pydantic=AuthResult
        )
        return Crew(agents=[agent], tasks=[task], process=Process.sequential)
```

### Pattern 3: Phone Detection (Code-based, NOT an Agent)

**What:** Deterministic lookup against `WhatsAppSession` table. Returns `{user_exists, session_status, user_id}`.

**When to use:** At the start of every conversation, before routing to any agent.

**Example:**
```python
# Reuses existing WhatsAppSession model from src/models/whatsapp_session.py
from datetime import datetime, timezone
from sqlalchemy.orm import Session
from src.models.whatsapp_session import WhatsAppSession

def detect_phone_session(phone_number: str, db_session: Session) -> dict:
    """Deterministic phone detection — no LLM involved."""
    # Normalize to E.164
    normalized = normalize_phone(phone_number)

    session = db_session.query(WhatsAppSession).filter(
        WhatsAppSession.phone_number == normalized
    ).first()

    if session is None:
        return {"user_exists": False, "session_status": "none", "user_id": None}

    if session.is_expired:  # WhatsAppSession.is_expired property already exists
        return {"user_exists": True, "session_status": "expired", "user_id": str(session.user_id)}

    return {"user_exists": True, "session_status": "active", "user_id": str(session.user_id)}
```

**KEY FINDING:** `WhatsAppSession` model (`src/models/whatsapp_session.py`) already exists with:
- `phone_number` (unique, indexed, E.164)
- `user_id` (Supabase Auth UUID)
- `tenant_id`
- `expires_at` (set to now + 24hr on creation)
- `is_expired` property
This is exactly what the context requires. No new table needed.

### Pattern 4: Crew Server (Standalone FastAPI)

**What:** A separate FastAPI process (not main.py) that exposes `/chat` and `/session/reset` endpoints. Streamlit calls it via httpx.

**When to use:** Keeps CrewAI crew lifecycle separate from the production API.

**Example:**
```python
# src/api/v1/intake_agent.py or crew_server.py (separate entry point)
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

crew_app = FastAPI(title="SALGA Crew Server")

class ChatRequest(BaseModel):
    phone: str
    message: str
    language: str = "en"
    municipality_id: str | None = None
    session_override: str | None = None  # "expired" | "new" | None

class ChatResponse(BaseModel):
    reply: str
    agent_name: str
    session_status: str
    debug: dict  # agent state, conversation turns, last API response

@crew_app.post("/api/v1/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    # 1. Detect phone session (deterministic)
    # 2. If active session: route to intake agent
    # 3. If expired/none: route to auth agent
    # 4. Return ChatResponse
    ...
```

### Pattern 5: Streamlit WhatsApp-style Chat

**What:** `st.chat_message` with `role="user"` (right-aligned in Streamlit) and `role="assistant"` (left-aligned). Session state tracks message history.

**When to use:** Main chat area of Streamlit dashboard.

**Example:**
```python
# Source: Streamlit 1.53.1 — st.chat_message is available
import streamlit as st

# Initialize session state
if "messages" not in st.session_state:
    st.session_state.messages = []

# Render existing messages
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Chat input at bottom
if prompt := st.chat_input("Type your message..."):
    # Add user message
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Call crew server via httpx
    response = httpx.post("http://localhost:8001/api/v1/chat", json={...})
    reply = response.json()["reply"]

    # Add agent reply (role="assistant" = left side, no label in main view)
    st.session_state.messages.append({"role": "assistant", "content": reply})
    with st.chat_message("assistant"):
        st.markdown(reply)
```

### Anti-Patterns to Avoid

- **Passing DeepSeek model as string to Agent:** `Agent(llm="deepseek-chat")` will not work with custom base_url. Always use `crewai.LLM` object.
- **Running CrewAI crew inside Streamlit event loop:** CrewAI `crew.kickoff()` is synchronous and blocking. Either use `asyncio.run()` or call it via httpx to the crew server instead.
- **Using `WhatsAppSession` for auth session without checking `is_expired`:** Always check `session.is_expired` before treating a session as active.
- **Creating new session table:** The existing `WhatsAppSession` table already satisfies all phone detection requirements. Adding another session table creates duplication.
- **Importing `src.main` from Streamlit:** The Streamlit app must be a completely separate process. Do NOT import the FastAPI app object.
- **Setting `memory=True` on AuthCrew:** Auth conversations contain sensitive PII (phone, OTP). Keep `memory=False` (same reasoning as GBV crew).

---

## Don't Hand-Roll

| Problem | Don't Build | Use Instead | Why |
|---------|-------------|-------------|-----|
| LLM API client for DeepSeek | Custom HTTP client to DeepSeek API | `crewai.LLM` + LiteLLM | LiteLLM handles retries, token counting, provider routing |
| Chat bubble CSS | Custom HTML/CSS bubbles | `st.chat_message(role)` | Streamlit 1.53.1 has built-in WhatsApp-style chat UI |
| Phone normalization | Custom regex | Existing `lookup_user_by_phone()` in whatsapp.py | Already handles +27 vs 0 prefix conversion (see `src/api/v1/whatsapp.py:69`) |
| Supabase OTP sending | Direct Supabase REST calls | `supabase_admin.auth.sign_in_with_otp()` | Already implemented in `src/api/v1/auth.py:309` |
| Session expiry logic | Custom datetime comparison | `WhatsAppSession.is_expired` property | Already implemented in `src/models/whatsapp_session.py:60` |
| JWT token creation in tests | Custom JWT builder | `create_supabase_access_token()` in conftest.py | Already exists in test infrastructure |

**Key insight:** Most of what this phase needs is already partially built. The existing auth.py, whatsapp.py, WhatsAppSession model, and ConversationManager cover the infrastructure. The work is wiring CrewAI agents to DeepSeek and building the Streamlit dashboard on top.

---

## Common Pitfalls

### Pitfall 1: CrewAI OPENAI_API_KEY Validation
**What goes wrong:** CrewAI/LiteLLM may still check for `OPENAI_API_KEY` even when using a custom provider. Tests and Streamlit will fail with "OpenAI API key not found" even though DeepSeek API key is set correctly.
**Why it happens:** LiteLLM's fallback validation logic; CrewAI agents sometimes initialize an implicit OpenAI check.
**How to avoid:** Set `OPENAI_API_KEY="dummy"` in the `.env` file (or in test setup) alongside `DEEPSEEK_API_KEY`. This is a dummy value that prevents the validation error without sending any requests to OpenAI.
**Warning signs:** `openai.AuthenticationError` or "OPENAI_API_KEY not found" in stack traces when using DeepSeek.

### Pitfall 2: crew.kickoff() is Synchronous and Blocking
**What goes wrong:** Calling `crew.kickoff()` inside an async FastAPI route or Streamlit callback freezes the event loop.
**Why it happens:** CrewAI `kickoff()` is synchronous (confirmed by existing code in both municipal_crew.py and gbv_crew.py which call it synchronously in the `async def kickoff()` wrapper).
**How to avoid:** In the crew server, use `asyncio.get_event_loop().run_in_executor(None, crew.kickoff, inputs)` or run in a ThreadPoolExecutor. In Streamlit, call the crew server via httpx (HTTP boundary handles the sync/async gap).
**Warning signs:** Streamlit UI freezes during agent execution; FastAPI request times out.

### Pitfall 3: Auth Agent Multi-Turn State
**What goes wrong:** Each call to `crew.kickoff()` is stateless — the auth agent won't remember previous turns (e.g., that OTP was sent in turn 1).
**Why it happens:** CrewAI tasks are single-shot by design. Multi-turn conversation history must be passed via the task description or inputs.
**How to avoid:** Store auth conversation state in Redis (using existing `ConversationManager`) and include the full conversation history in the task `description` on each turn. The auth task description should include: `context["conversation_history"]` as prior turns.
**Warning signs:** Auth agent asks for OTP again after user already provided it; asks for phone number after user already gave it.

### Pitfall 4: Streamlit Session State vs Server State
**What goes wrong:** Streamlit reruns the entire script on every interaction. Session state not stored in `st.session_state` is lost on rerun.
**Why it happens:** Streamlit's execution model — every widget interaction triggers a full script rerun.
**How to avoid:** Store ALL conversation state in `st.session_state`: messages list, phone number, current agent, debug info. Never store state in module-level variables.
**Warning signs:** Chat history disappears on each message; phone number resets unexpectedly.

### Pitfall 5: Proof of Residence Upload in Auth Agent
**What goes wrong:** Auth agent needs to handle file upload (OCR), but CrewAI tools must be synchronous. File upload via Streamlit goes through a different path than the agent tool.
**Why it happens:** Streamlit `st.file_uploader` is UI-level, while the auth agent tool calls OCR service (which is async).
**How to avoid:** Handle proof of residence upload as a separate Streamlit step OUTSIDE the agent conversation. Upload the file via a direct API call to the existing `/api/v1/uploads/` endpoint, get back a `document_id`, then pass `document_id` to the auth agent tool as a parameter. The agent tool calls `ocr_service.verify_document(document_id)` synchronously.
**Warning signs:** "Cannot run async function in sync context" from CrewAI tool execution.

### Pitfall 6: GBV Security in Test Dashboard
**What goes wrong:** The test dashboard might log or display GBV conversation content in the debug panel, violating the GBV firewall.
**Why it happens:** Debug panels that show "last API response" or "conversation state" would expose sensitive content.
**How to avoid:** When `is_gbv=True`, the debug panel must show only metadata (agent name, turn count, status) — NOT conversation content. Add `if scenario == "gbv": debug_panel.redact_content()`. The existing GBV firewall in the API layer (`is_sensitive=True` flag) must be respected.
**Warning signs:** Full GBV conversation text appearing in Streamlit debug panel.

---

## Code Examples

Verified patterns from existing codebase + official sources:

### DeepSeek LLM Configuration for CrewAI
```python
# Based on: crewai docs (https://docs.crewai.com/en/learn/llm-connections)
# + DeepSeek API docs (https://api-docs.deepseek.com/)
from crewai import LLM
from src.core.config import settings

def get_deepseek_llm() -> LLM:
    return LLM(
        model="deepseek/deepseek-chat",  # LiteLLM provider/model format
        base_url="https://api.deepseek.com/v1",
        api_key=settings.DEEPSEEK_API_KEY,
        temperature=0.7,
        max_tokens=2048,
    )
```

### Adding DEEPSEEK_API_KEY to Settings (src/core/config.py)
```python
# Add to Settings class — follows existing pattern exactly
DEEPSEEK_API_KEY: str = Field(default="", description="DeepSeek API key for LLM")
DEEPSEEK_BASE_URL: str = Field(
    default="https://api.deepseek.com/v1",
    description="DeepSeek API base URL (OpenAI-compatible)"
)
CREW_SERVER_URL: str = Field(
    default="http://localhost:8001",
    description="URL of the crew server for Streamlit to connect to"
)
```

### Updating Existing Crews to Use LLM Object
```python
# src/agents/crews/municipal_crew.py — minimal change
# BEFORE: llm=self.llm_model  (string "gpt-4o")
# AFTER:
from crewai import LLM

class MunicipalCrew:
    def __init__(self, language: str = "en", llm: LLM | None = None):
        self.language = language if language in ["en", "zu", "af"] else "en"
        self.llm = llm or get_deepseek_llm()  # Default to DeepSeek

    def create_crew(self, message, user_id, tenant_id) -> Crew:
        agent = Agent(
            ...
            llm=self.llm,  # Pass LLM object, not string
            ...
        )
```

### Phone Detection (using existing WhatsAppSession)
```python
# Reuses: src/models/whatsapp_session.py (WhatsAppSession model)
# Reuses: lookup pattern from src/api/v1/whatsapp.py:69
from src.models.whatsapp_session import WhatsAppSession

def detect_phone_session(phone_number: str, db_session) -> dict:
    """Returns minimal context for auth agent. Not an agent itself."""
    normalized = _normalize_phone(phone_number)  # Reuse whatsapp.py pattern
    session = db_session.query(WhatsAppSession).filter(
        WhatsAppSession.phone_number == normalized
    ).first()

    if session is None:
        return {"user_exists": False, "session_status": "none", "user_id": None}
    if session.is_expired:
        return {"user_exists": True, "session_status": "expired",
                "user_id": str(session.user_id)}
    return {"user_exists": True, "session_status": "active",
            "user_id": str(session.user_id)}
```

### Auth Tool: Send OTP (wraps existing Supabase call)
```python
# Wraps: supabase_admin.auth.sign_in_with_otp() (already in auth.py:309)
# Must be synchronous for CrewAI tool
from crewai.tools import tool
from supabase import Client

@tool("send_otp")
def send_otp_tool(phone_or_email: str, channel: str = "sms") -> str:
    """Send OTP to phone or email. Returns success/error message."""
    supabase = get_supabase_admin()
    try:
        if channel == "sms":
            supabase.auth.sign_in_with_otp({"phone": phone_or_email})
        else:
            supabase.auth.sign_in_with_otp({"email": phone_or_email})
        return f"OTP sent successfully to {channel}"
    except Exception as e:
        return f"Failed to send OTP: {str(e)}"
```

### Supabase User Creation by Auth Agent
```python
# Mirrors: src/api/v1/auth.py:104 (supabase_admin.auth.admin.create_user)
@tool("create_supabase_user")
def create_supabase_user_tool(
    email: str,
    phone: str,
    full_name: str,
    municipality_id: str,
    residence_verified: bool = False
) -> dict:
    """Create Supabase Auth user with role and tenant_id in user_metadata."""
    supabase = get_supabase_admin()
    response = supabase.auth.admin.create_user({
        "email": email,
        "phone": phone,
        "email_confirm": True,
        "app_metadata": {
            "role": "citizen",
            "tenant_id": municipality_id
        },
        "user_metadata": {
            "full_name": full_name,
            "residence_verified": residence_verified,
            "preferred_language": "en"  # auth agent sets this from context
        }
    })
    return {"user_id": response.user.id, "email": response.user.email}
```

### Streamlit Chat with Session State
```python
# Source: Streamlit 1.53.1 docs — st.chat_message, st.chat_input
import streamlit as st
import httpx
from src.core.config import settings

def render_chat():
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Render chat history
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):  # "user" = right, "assistant" = left
            st.write(msg["content"])

    if prompt := st.chat_input("Type a message..."):
        st.session_state.messages.append({"role": "user", "content": prompt})

        # Call crew server (synchronous httpx in Streamlit is OK — not async context)
        try:
            resp = httpx.post(
                f"{settings.CREW_SERVER_URL}/api/v1/chat",
                json={
                    "phone": st.session_state.get("phone", ""),
                    "message": prompt,
                    "language": st.session_state.get("language", "en"),
                },
                timeout=60.0
            )
            resp.raise_for_status()
            data = resp.json()
            reply = data["reply"]
            st.session_state.debug_info = data.get("debug", {})
        except httpx.HTTPStatusError as e:
            reply = "DeepSeek API unavailable, please retry"
        except httpx.TimeoutException:
            reply = "Request timed out. Please retry."

        st.session_state.messages.append({"role": "assistant", "content": reply})
        st.rerun()
```

### Test Pattern: Mock DeepSeek LLM (follows existing test style)
```python
# Follows: tests/test_municipal_crew.py pattern
import os
os.environ["OPENAI_API_KEY"] = "sk-test-fake-key-for-unit-tests"
os.environ["DEEPSEEK_API_KEY"] = "sk-deepseek-test-fake-key"

from unittest.mock import patch, MagicMock
from crewai import LLM

@pytest.fixture
def mock_deepseek_llm():
    """Mock DeepSeek LLM to prevent real API calls in tests."""
    mock_llm = MagicMock(spec=LLM)
    mock_llm.call.return_value = "Mocked LLM response"
    return mock_llm

def test_auth_crew_initialization(mock_deepseek_llm):
    with patch("src.agents.crews.auth_crew.get_deepseek_llm", return_value=mock_deepseek_llm):
        crew = AuthCrew(language="en")
        assert crew.language == "en"
```

---

## State of the Art

| Old Approach | Current Approach | When Changed | Impact |
|--------------|------------------|--------------|--------|
| `Agent(llm="gpt-4o")` string | `Agent(llm=LLM(model=..., base_url=..., api_key=...))` | CrewAI ~0.60+ | Enables custom providers cleanly |
| Streamlit custom HTML chat | `st.chat_message(role)` built-in | Streamlit 1.31.0+ | No custom CSS needed for chat bubbles |
| CrewAI global OPENAI_API_KEY | Per-LLM api_key parameter | CrewAI 0.9+ | Multiple providers without global env conflict |

**Deprecated/outdated:**
- `Agent(llm="gpt-4o")` as a string — still works for OpenAI, but NOT for custom base_url providers. Use `LLM` object.
- `OPENAI_MODEL_NAME` env var for non-OpenAI models — works but fragile; explicit LLM object is cleaner.

---

## Open Questions

1. **DeepSeek V3.2 vs V3 model name**
   - What we know: DeepSeek API docs show `deepseek-chat` as the model name for DeepSeek V3 family. The context says "V3.2" specifically.
   - What's unclear: Whether "V3.2" maps to `deepseek-chat` or a different model ID on DeepSeek's API.
   - Recommendation: At implementation time, call `GET https://api.deepseek.com/models` with the DEEPSEEK_API_KEY to list available models. Use `deepseek-chat` unless a `deepseek-chat-v3.2` or similar appears.

2. **Auth agent max_iter for multi-turn registration**
   - What we know: MunicipalCrew uses `max_iter=10`, GBVCrew uses `max_iter=8`. Auth with full registration flow (collect phone -> OTP -> name -> email -> proof of residence -> municipality) needs more turns.
   - What's unclear: Whether CrewAI `max_iter` is the right lever for multi-turn or whether conversation history injection is needed.
   - Recommendation: Set `max_iter=15` for AuthCrew. Include full conversation history in task description on each call (store in Redis via ConversationManager).

3. **Crew server port and API key for Streamlit**
   - What we know: Streamlit connects to crew server via HTTP. The context says API-first security.
   - What's unclear: Whether crew server needs authentication (bearer token) or if local-only binding is sufficient for developer tool.
   - Recommendation: Crew server binds to `localhost:8001` only (not `0.0.0.0`). Add a simple `X-API-Key` header check using a `CREW_SERVER_API_KEY` env var. Streamlit reads this from settings. Provides baseline security without full OAuth overhead for a dev tool.

---

## Sources

### Primary (HIGH confidence)
- Existing codebase: `src/agents/crews/municipal_crew.py`, `gbv_crew.py` — confirmed CrewAI Agent/Crew/Task pattern
- Existing codebase: `src/models/whatsapp_session.py` — confirmed WhatsAppSession model with is_expired, 24hr expiry
- Existing codebase: `src/api/v1/auth.py` — confirmed Supabase OTP send/verify pattern
- Existing codebase: `src/core/config.py` — confirmed Settings class pattern for new env vars
- Existing codebase: `src/agents/tools/ticket_tool.py` — confirmed synchronous tool pattern for CrewAI
- Existing codebase: `tests/test_municipal_crew.py` — confirmed test mocking pattern (OPENAI_API_KEY dummy, Session mock)
- Existing codebase: `tests/conftest.py` — confirmed test infrastructure (JWT fixtures, db_session, mock_supabase_admin)
- pip show crewai: Version 1.8.1 confirmed installed
- pip show streamlit: Version 1.53.1 confirmed installed
- grep .env: DEEPSEEK_API_KEY confirmed present (count=1)

### Secondary (MEDIUM confidence)
- [DeepSeek API docs](https://api-docs.deepseek.com/) — base_url `https://api.deepseek.com/v1`, model name `deepseek-chat`, OpenAI-compatible
- [CrewAI LLM connections docs](https://docs.crewai.com/en/learn/llm-connections) — `LLM(model=..., base_url=..., api_key=...)` pattern confirmed
- WebSearch: CrewAI OPENAI_API_KEY validation issue with custom providers — documented community issue

### Tertiary (LOW confidence)
- DeepSeek "V3.2" model name mapping — could not verify `deepseek-chat` is the exact model for V3.2 vs V3. Needs runtime verification via models API.

---

## Metadata

**Confidence breakdown:**
- Standard stack: HIGH — all libraries already installed and in use in codebase
- Architecture: HIGH — follows existing MunicipalCrew/GBVCrew patterns exactly
- DeepSeek API endpoint: MEDIUM — from official docs, model name V3.2 needs runtime verification
- Pitfalls: HIGH — most from direct codebase analysis; CrewAI OPENAI_API_KEY issue from multiple community sources

**Research date:** 2026-02-17
**Valid until:** 2026-03-17 (30 days — CrewAI and Streamlit APIs are relatively stable)
