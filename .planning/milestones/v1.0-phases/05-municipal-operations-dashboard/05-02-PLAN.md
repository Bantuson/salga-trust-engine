---
phase: 05-municipal-operations-dashboard
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/services/event_broadcaster.py
  - src/api/v1/events.py
  - src/api/v1/export.py
  - src/main.py
autonomous: true

must_haves:
  truths:
    - "SSE endpoint streams real-time ticket events to connected dashboard clients"
    - "Redis Pub/Sub broadcasts events across multiple server instances"
    - "Ward councillor receives only events for their ward"
    - "Manager can export filtered ticket data as CSV or Excel file"
    - "Export excludes GBV/sensitive tickets (SEC-05)"
  artifacts:
    - path: "src/services/event_broadcaster.py"
      provides: "Redis Pub/Sub event broadcasting"
      contains: "class EventBroadcaster"
    - path: "src/api/v1/events.py"
      provides: "SSE streaming endpoint"
      contains: "EventSourceResponse"
    - path: "src/api/v1/export.py"
      provides: "CSV/Excel export endpoint"
      contains: "StreamingResponse"
  key_links:
    - from: "src/api/v1/events.py"
      to: "src/services/event_broadcaster.py"
      via: "EventBroadcaster subscribe"
      pattern: "broadcaster.subscribe"
    - from: "src/api/v1/events.py"
      to: "src/main.py"
      via: "Router registration"
      pattern: "events.router"
    - from: "src/api/v1/export.py"
      to: "src/main.py"
      via: "Router registration"
      pattern: "export.router"
---

<objective>
Create real-time SSE event streaming and data export endpoints for the municipal operations dashboard.

Purpose: OPS-04 requires real-time dashboard updates without page refresh (SSE). OPS-02 requires CSV/Excel export capability. Both require RBAC enforcement and SEC-05 GBV exclusion.
Output: SSE event stream endpoint + Redis Pub/Sub broadcaster + CSV/Excel export endpoint
</objective>

<execution_context>
@C:/Users/Bantu/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/Bantu/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-municipal-operations-dashboard/05-RESEARCH.md
@src/core/config.py
@src/api/deps.py
@src/models/ticket.py
@src/models/user.py
@src/main.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Redis Pub/Sub event broadcaster and SSE endpoint</name>
  <files>src/services/event_broadcaster.py, src/api/v1/events.py</files>
  <action>
    1. Create `src/services/event_broadcaster.py`:

       ```python
       """Redis Pub/Sub event broadcaster for real-time dashboard updates.

       Broadcasts ticket events (status changes, new assignments, SLA breaches)
       to all connected SSE clients via Redis Pub/Sub channels.
       Each municipality has its own channel: "dashboard:{municipality_id}".
       """
       import json
       import logging
       from typing import AsyncGenerator
       from uuid import UUID

       import redis.asyncio as redis

       from src.core.config import settings

       logger = logging.getLogger(__name__)


       class EventBroadcaster:
           """Redis Pub/Sub broadcaster for dashboard events."""

           def __init__(self):
               self._redis_client = None
               self._pubsub = None

           async def _get_redis(self):
               if self._redis_client is None:
                   self._redis_client = redis.from_url(
                       settings.REDIS_URL,
                       decode_responses=True
                   )
               return self._redis_client

           async def publish(self, municipality_id: str, event: dict) -> int:
               """Publish event to municipality's dashboard channel.

               Args:
                   municipality_id: Target municipality UUID string
                   event: Event dict with 'type', 'data', optional 'ward_id'
                       type: "ticket_updated", "ticket_created", "sla_breach", "assignment_changed"
                       data: Event payload (ticket_id, status, category, etc.)
                       ward_id: Ward identifier for WARD_COUNCILLOR filtering

               Returns:
                   Number of subscribers that received the message
               """
               r = await self._get_redis()
               channel = f"dashboard:{municipality_id}"
               payload = json.dumps(event)
               count = await r.publish(channel, payload)
               logger.debug(f"Published {event.get('type')} to {channel} ({count} subscribers)")
               return count

           async def subscribe(self, municipality_id: str) -> AsyncGenerator[dict, None]:
               """Subscribe to municipality's dashboard channel and yield events.

               Args:
                   municipality_id: Municipality UUID string

               Yields:
                   Event dicts as they arrive
               """
               r = await self._get_redis()
               pubsub = r.pubsub()
               channel = f"dashboard:{municipality_id}"

               await pubsub.subscribe(channel)
               logger.info(f"Subscribed to {channel}")

               try:
                   async for message in pubsub.listen():
                       if message["type"] == "message":
                           try:
                               yield json.loads(message["data"])
                           except json.JSONDecodeError:
                               logger.warning(f"Invalid JSON in {channel}: {message['data']}")
               finally:
                   await pubsub.unsubscribe(channel)
                   await pubsub.close()
                   logger.info(f"Unsubscribed from {channel}")

           async def close(self):
               """Close Redis connection."""
               if self._redis_client:
                   await self._redis_client.close()
                   self._redis_client = None
       ```

    2. Create `src/api/v1/events.py`:

       ```python
       """SSE (Server-Sent Events) endpoint for real-time dashboard updates.

       Streams ticket events to connected dashboard clients. Uses Redis Pub/Sub
       to receive events published by other parts of the system (ticket updates,
       SLA breaches, assignments). Filters events by user role:
       - MANAGER/ADMIN: All events for their municipality
       - WARD_COUNCILLOR: Only events matching their ward
       """
       import asyncio
       import json
       import logging
       from uuid import uuid4

       from fastapi import APIRouter, Depends, HTTPException, Query, status
       from sse_starlette.sse import EventSourceResponse

       from src.api.deps import get_current_user
       from src.models.user import User, UserRole
       from src.services.event_broadcaster import EventBroadcaster

       logger = logging.getLogger(__name__)

       router = APIRouter(prefix="/dashboard", tags=["dashboard-events"])


       @router.get("/events")
       async def stream_dashboard_events(
           current_user: User = Depends(get_current_user),
           ward_id: str | None = Query(None, description="Ward filter for WARD_COUNCILLOR"),
       ):
           """SSE endpoint for real-time dashboard event streaming.

           Streams events:
           - ticket_updated: Status or assignment changes
           - ticket_created: New ticket submitted
           - sla_breach: Ticket exceeded SLA deadline
           - assignment_changed: Ticket reassigned

           Auto-reconnects on disconnect (browser EventSource API).
           """
           # RBAC: Only dashboard users
           allowed_roles = [UserRole.MANAGER, UserRole.ADMIN, UserRole.WARD_COUNCILLOR]
           if current_user.role not in allowed_roles:
               raise HTTPException(
                   status_code=status.HTTP_403_FORBIDDEN,
                   detail="Dashboard access requires manager, admin, or ward councillor role"
               )

           municipality_id = str(current_user.tenant_id)
           broadcaster = EventBroadcaster()

           async def event_generator():
               try:
                   # Send initial heartbeat
                   yield {
                       "event": "connected",
                       "data": json.dumps({"status": "connected", "municipality_id": municipality_id}),
                       "id": str(uuid4()),
                   }

                   async for event in broadcaster.subscribe(municipality_id):
                       # RBAC: Ward councillor filtering
                       if current_user.role == UserRole.WARD_COUNCILLOR:
                           event_ward = event.get("ward_id")
                           if ward_id and event_ward and event_ward != ward_id:
                               continue  # Skip events for other wards

                       yield {
                           "event": event.get("type", "message"),
                           "data": json.dumps(event.get("data", {})),
                           "id": str(uuid4()),
                       }
               except asyncio.CancelledError:
                   logger.info(f"SSE client disconnected: {municipality_id}")
               finally:
                   await broadcaster.close()

           return EventSourceResponse(event_generator())
       ```

    3. Install sse-starlette:
       Run `pip install "sse-starlette>=2.1.0"` and add `sse-starlette>=2.1.0` to pyproject.toml under `[project] dependencies`.

    Note: The EventBroadcaster uses the existing REDIS_URL from settings (already configured in Phase 4 for Celery). The SSE endpoint lives under /dashboard/ namespace alongside the metrics endpoints from Plan 01. When both plans are merged, the main.py will have one dashboard router from Plan 01 and one events router from this plan -- they use the same /dashboard prefix but different sub-paths (/dashboard/metrics vs /dashboard/events).
  </action>
  <verify>
    - `python -c "from src.services.event_broadcaster import EventBroadcaster; print('OK')"` succeeds
    - `python -c "from src.api.v1.events import router; print([r.path for r in router.routes])"` shows /dashboard/events
    - `pip show sse-starlette` shows installed version >= 2.1.0
  </verify>
  <done>
    - EventBroadcaster can publish and subscribe to Redis Pub/Sub channels
    - SSE endpoint streams events with RBAC filtering (ward councillor sees only their ward)
    - sse-starlette installed and added to project dependencies
  </done>
</task>

<task type="auto">
  <name>Task 2: Create CSV/Excel export endpoint</name>
  <files>src/api/v1/export.py, src/main.py</files>
  <action>
    1. Create `src/api/v1/export.py`:

       ```python
       """Data export endpoints for CSV and Excel download.

       Provides server-side export of filtered ticket data. Supports both CSV
       and Excel (.xlsx) formats. Uses StreamingResponse for memory efficiency.
       SEC-05: GBV/sensitive tickets are always excluded from exports.
       """
       import csv
       import io
       import logging
       from datetime import datetime, timezone
       from uuid import UUID

       from fastapi import APIRouter, Depends, HTTPException, Query, status
       from fastapi.responses import StreamingResponse
       from sqlalchemy import desc, func, or_, select
       from sqlalchemy.ext.asyncio import AsyncSession

       from src.api.deps import get_current_user, get_db
       from src.models.ticket import Ticket
       from src.models.user import User, UserRole

       logger = logging.getLogger(__name__)

       router = APIRouter(prefix="/export", tags=["export"])


       EXPORT_COLUMNS = [
           ("Tracking Number", "tracking_number"),
           ("Category", "category"),
           ("Status", "status"),
           ("Severity", "severity"),
           ("Description", "description"),
           ("Address", "address"),
           ("Language", "language"),
           ("Created", "created_at"),
           ("SLA Response Deadline", "sla_response_deadline"),
           ("SLA Resolution Deadline", "sla_resolution_deadline"),
           ("First Responded", "first_responded_at"),
           ("Resolved At", "resolved_at"),
           ("Escalated At", "escalated_at"),
       ]


       @router.get("/tickets/csv")
       async def export_tickets_csv(
           current_user: User = Depends(get_current_user),
           db: AsyncSession = Depends(get_db),
           status_filter: str | None = Query(None, alias="status"),
           category: str | None = None,
           ward_id: str | None = None,
           search: str | None = None,
       ):
           """Export filtered tickets as CSV file.

           Applies same RBAC and filters as list_tickets endpoint.
           SEC-05: GBV/sensitive tickets always excluded.
           Max 10,000 rows per export.
           """
           allowed_roles = [UserRole.MANAGER, UserRole.ADMIN, UserRole.WARD_COUNCILLOR]
           if current_user.role not in allowed_roles:
               raise HTTPException(
                   status_code=status.HTTP_403_FORBIDDEN,
                   detail="Export requires manager, admin, or ward councillor role"
               )

           tickets = await _fetch_export_tickets(
               db, current_user, status_filter, category, ward_id, search
           )

           # Generate CSV
           output = io.StringIO()
           writer = csv.writer(output)

           # Header row
           writer.writerow([col[0] for col in EXPORT_COLUMNS])

           # Data rows
           for ticket in tickets:
               row = []
               for _, attr in EXPORT_COLUMNS:
                   value = getattr(ticket, attr, None)
                   if isinstance(value, datetime):
                       value = value.strftime("%Y-%m-%d %H:%M:%S")
                   elif value is None:
                       value = ""
                   row.append(str(value))
               writer.writerow(row)

           output.seek(0)

           timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
           filename = f"tickets_export_{timestamp}.csv"

           return StreamingResponse(
               iter([output.getvalue()]),
               media_type="text/csv",
               headers={"Content-Disposition": f"attachment; filename={filename}"}
           )


       @router.get("/tickets/excel")
       async def export_tickets_excel(
           current_user: User = Depends(get_current_user),
           db: AsyncSession = Depends(get_db),
           status_filter: str | None = Query(None, alias="status"),
           category: str | None = None,
           ward_id: str | None = None,
           search: str | None = None,
       ):
           """Export filtered tickets as Excel (.xlsx) file.

           Applies same RBAC and filters as list_tickets endpoint.
           SEC-05: GBV/sensitive tickets always excluded.
           Max 10,000 rows per export. Uses openpyxl for .xlsx generation.
           """
           allowed_roles = [UserRole.MANAGER, UserRole.ADMIN, UserRole.WARD_COUNCILLOR]
           if current_user.role not in allowed_roles:
               raise HTTPException(
                   status_code=status.HTTP_403_FORBIDDEN,
                   detail="Export requires manager, admin, or ward councillor role"
               )

           tickets = await _fetch_export_tickets(
               db, current_user, status_filter, category, ward_id, search
           )

           try:
               from openpyxl import Workbook
           except ImportError:
               # Fallback: if openpyxl not installed, return 501
               raise HTTPException(
                   status_code=status.HTTP_501_NOT_IMPLEMENTED,
                   detail="Excel export requires openpyxl. Use CSV export instead."
               )

           wb = Workbook()
           ws = wb.active
           ws.title = "Tickets"

           # Header row
           headers = [col[0] for col in EXPORT_COLUMNS]
           ws.append(headers)

           # Bold headers
           from openpyxl.styles import Font
           for cell in ws[1]:
               cell.font = Font(bold=True)

           # Data rows
           for ticket in tickets:
               row = []
               for _, attr in EXPORT_COLUMNS:
                   value = getattr(ticket, attr, None)
                   if isinstance(value, datetime):
                       value = value.strftime("%Y-%m-%d %H:%M:%S")
                   elif value is None:
                       value = ""
                   row.append(str(value))
               ws.append(row)

           # Auto-size columns (approximate)
           for col_idx, (header, _) in enumerate(EXPORT_COLUMNS, 1):
               ws.column_dimensions[chr(64 + col_idx) if col_idx <= 26 else "A"].width = max(len(header) + 2, 15)

           # Write to bytes buffer
           output = io.BytesIO()
           wb.save(output)
           output.seek(0)

           timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
           filename = f"tickets_export_{timestamp}.xlsx"

           return StreamingResponse(
               output,
               media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
               headers={"Content-Disposition": f"attachment; filename={filename}"}
           )


       async def _fetch_export_tickets(
           db: AsyncSession,
           current_user: User,
           status_filter: str | None,
           category: str | None,
           ward_id: str | None,
           search: str | None,
           max_rows: int = 10000,
       ) -> list:
           """Fetch tickets for export with RBAC and filters.

           SEC-05: Always excludes GBV/sensitive tickets.
           """
           query = select(Ticket).where(Ticket.is_sensitive == False)

           # Tenant filter
           query = query.where(Ticket.tenant_id == current_user.tenant_id)

           # Status filter
           if status_filter:
               query = query.where(Ticket.status == status_filter.lower())

           # Category filter
           if category:
               query = query.where(Ticket.category == category.lower())

           # Ward filter
           if ward_id:
               query = query.where(Ticket.address.ilike(f"%{ward_id}%"))

           # Search
           if search:
               query = query.where(
                   or_(
                       Ticket.tracking_number.ilike(f"%{search}%"),
                       Ticket.description.ilike(f"%{search}%"),
                   )
               )

           # Order and limit
           query = query.order_by(desc(Ticket.created_at)).limit(max_rows)

           result = await db.execute(query)
           return result.scalars().all()
       ```

    2. Install openpyxl (optional, for Excel export):
       Run `pip install openpyxl>=3.1.0` and add `openpyxl>=3.1.0` to pyproject.toml under `[project] dependencies`.

    3. In `src/main.py`:
       - Add `from src.api.v1 import events, export` to the import line (after `dashboard` which Plan 01 adds -- if running in parallel, just add events + export to the existing import)
       - Add `app.include_router(events.router, prefix="/api/v1")` and `app.include_router(export.router, prefix="/api/v1")` after the dashboard router line

    Note: This plan touches `src/main.py` which Plan 01 also modifies. Since both are Wave 1 (parallel), the executor should merge both changes into main.py. The changes are additive (import + include_router) so they can't conflict structurally. If a merge issue arises, the second plan to execute should read the current main.py and add its lines.
  </action>
  <verify>
    - `python -c "from src.services.event_broadcaster import EventBroadcaster; print('OK')"` succeeds
    - `python -c "from src.api.v1.events import router; print([r.path for r in router.routes])"` shows /dashboard/events
    - `python -c "from src.api.v1.export import router; print([r.path for r in router.routes])"` shows /export/tickets/csv and /export/tickets/excel
    - `pip show sse-starlette` shows installed
    - `python -c "from src.main import app; routes = [r.path for r in app.routes]; print([r for r in routes if 'export' in r or 'events' in r])"` shows registered routes
  </verify>
  <done>
    - EventBroadcaster publishes/subscribes via Redis Pub/Sub
    - SSE endpoint streams filtered events with RBAC enforcement
    - CSV export endpoint returns StreamingResponse with ticket data
    - Excel export endpoint returns .xlsx file (graceful fallback if openpyxl missing)
    - SEC-05: All exports exclude GBV/sensitive tickets
    - Both routers registered in main.py
  </done>
</task>

</tasks>

<verification>
- All existing tests pass: `python -m pytest tests/ -x --timeout=30 -q` (265+ tests, 0 failures)
- New modules importable: `python -c "from src.services.event_broadcaster import EventBroadcaster; from src.api.v1.events import router; from src.api.v1.export import router"`
- SSE endpoint exists at /api/v1/dashboard/events
- Export endpoints exist at /api/v1/export/tickets/csv and /api/v1/export/tickets/excel
</verification>

<success_criteria>
- Real-time SSE streaming works with Redis Pub/Sub
- CSV and Excel export endpoints functional with RBAC
- SEC-05 enforced on all event streams and exports
- Ward councillor filtering applied to SSE events
- Zero regressions on existing test suite
</success_criteria>

<output>
After completion, create `.planning/phases/05-municipal-operations-dashboard/05-02-SUMMARY.md`
</output>
